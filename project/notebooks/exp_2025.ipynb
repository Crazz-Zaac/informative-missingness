{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a064a422",
   "metadata": {},
   "source": [
    "## Show the tables in schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2ec9e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:23:13,287 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-06-13 14:23:13,287 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-06-13 14:23:13,288 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-06-13 14:23:13,288 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-06-13 14:23:13,289 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-06-13 14:23:13,289 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "Schema: mimiciv_icu\n",
      "2025-06-13 14:23:13,291 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-13 14:23:13,291 INFO sqlalchemy.engine.Engine SELECT table_name FROM information_schema.tables WHERE table_schema = %(schema)s\n",
      "2025-06-13 14:23:13,291 INFO sqlalchemy.engine.Engine [generated in 0.00060s] {'schema': 'mimiciv_icu'}\n",
      "['caregiver', 'chartevents', 'datetimeevents', 'd_items', 'icustays', 'ingredientevents', 'inputevents', 'outputevents', 'procedureevents']\n",
      "Schema: mimiciv_hosp\n",
      "2025-06-13 14:23:13,295 INFO sqlalchemy.engine.Engine SELECT table_name FROM information_schema.tables WHERE table_schema = %(schema)s\n",
      "2025-06-13 14:23:13,295 INFO sqlalchemy.engine.Engine [cached since 0.004075s ago] {'schema': 'mimiciv_hosp'}\n",
      "['admissions', 'd_hcpcs', 'diagnoses_icd', 'd_icd_diagnoses', 'd_icd_procedures', 'd_labitems', 'drgcodes', 'emar_detail', 'emar', 'hcpcsevents', 'labevents', 'microbiologyevents', 'omr', 'patients', 'pharmacy', 'poe_detail', 'poe', 'prescriptions', 'procedures_icd', 'provider', 'services', 'transfers']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))  # adding the parent directory of 'notebooks' to sys.path\n",
    "from db_utils.db_setup import Database\n",
    "from sqlalchemy import text\n",
    "engine = Database()\n",
    "schema_list = [\"mimiciv_icu\", \"mimiciv_hosp\"]\n",
    "for schema in schema_list:\n",
    "    print(f\"Schema: {schema}\")\n",
    "    tables = Database.show_tables_in_schema(engine, schema)\n",
    "    print(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526cc2c0",
   "metadata": {},
   "source": [
    "# Getting all `labevents` data and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb8590",
   "metadata": {},
   "source": [
    "##### Fetching `demographic` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "url = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(url)\n",
    "conn = engine.connect()\n",
    "cursor = conn.connection.cursor()\n",
    "\n",
    "# Creating a TEMPORARY table\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TEMP TABLE temp_cohort (\n",
    "        subject_id INT,\n",
    "        hadm_id INT,\n",
    "        admittime TIMESTAMP,\n",
    "        dischtime TIMESTAMP,\n",
    "        target  INT\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Loading the CSV and insert into temp_cohort\n",
    "cohort_df = pd.read_csv('../assets/cohort1_target.csv')\n",
    "cohort_df['admittime'] = pd.to_datetime(cohort_df['admittime'], errors='coerce')\n",
    "cohort_df['dischtime'] = pd.to_datetime(cohort_df['dischtime'], errors='coerce')\n",
    "\n",
    "values = list(cohort_df.itertuples(index=False, name=None))\n",
    "execute_values(cursor,\n",
    "    \"INSERT INTO temp_cohort (subject_id, hadm_id, admittime, dischtime, target) VALUES %s\",\n",
    "    values\n",
    ")\n",
    "\n",
    "# Fetching demographic data from admissions table\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT \n",
    "        c.subject_id,\n",
    "        c.hadm_id,\n",
    "        c.admittime,\n",
    "        c.dischtime,\n",
    "        c.target,\n",
    "        p.gender,\n",
    "        p.anchor_age,\n",
    "        a.race\n",
    "    FROM temp_cohort c\n",
    "    JOIN mimiciv_hosp.admissions a ON c.hadm_id = a.hadm_id\n",
    "    JOIN mimiciv_hosp.patients p ON a.subject_id = p.subject_id\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Finally creating DataFrame \n",
    "columns = ['subject_id', 'hadm_id', 'admittime', 'dischtime', 'target', 'gender', 'anchor_age', 'race']\n",
    "final_df = pd.DataFrame(rows, columns=columns)\n",
    "# Save the final DataFrame to a Parquet file\n",
    "final_df['admittime'] = pd.to_datetime(final_df['admittime'], errors='coerce')\n",
    "final_df['dischtime'] = pd.to_datetime(final_df['dischtime'], errors='coerce')\n",
    "final_df['anchor_age'] = pd.to_numeric(final_df['anchor_age'], errors='coerce')\n",
    "final_df['target'] = pd.to_numeric(final_df['target'], errors='coerce')\n",
    "final_df.to_parquet(\"../dataset/raw/cohort_with_demographic_data.parquet\", index=False)\n",
    "\n",
    "# Finalize\n",
    "conn.connection.commit()\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "469830e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>target</th>\n",
       "      <th>gender</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10010231</td>\n",
       "      <td>23835132</td>\n",
       "      <td>2118-04-02 11:54:00</td>\n",
       "      <td>2118-04-07 11:26:00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10010231</td>\n",
       "      <td>23835132</td>\n",
       "      <td>2118-04-02 11:54:00</td>\n",
       "      <td>2118-04-07 11:26:00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10010231</td>\n",
       "      <td>23835132</td>\n",
       "      <td>2118-04-02 11:54:00</td>\n",
       "      <td>2118-04-07 11:26:00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10010231</td>\n",
       "      <td>24995642</td>\n",
       "      <td>2118-02-21 13:30:00</td>\n",
       "      <td>2118-02-26 16:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10010231</td>\n",
       "      <td>24995642</td>\n",
       "      <td>2118-02-21 13:30:00</td>\n",
       "      <td>2118-02-26 16:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id           admittime           dischtime  target  \\\n",
       "0    10010231  23835132 2118-04-02 11:54:00 2118-04-07 11:26:00       0   \n",
       "1    10010231  23835132 2118-04-02 11:54:00 2118-04-07 11:26:00       0   \n",
       "2    10010231  23835132 2118-04-02 11:54:00 2118-04-07 11:26:00       0   \n",
       "3    10010231  24995642 2118-02-21 13:30:00 2118-02-26 16:50:00       0   \n",
       "4    10010231  24995642 2118-02-21 13:30:00 2118-02-26 16:50:00       0   \n",
       "\n",
       "  gender  anchor_age                          race  \n",
       "0      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "1      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "2      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "3      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "4      M          57  HISPANIC/LATINO - GUATEMALAN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demog_df = pd.read_parquet(\"../dataset/raw/cohort_with_demographic_data.parquet\")\n",
    "demog_df.head(5)  # Display the first 5 rows of the raw Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d057f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'F'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demog_df['gender'].unique()  # Check unique values in the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad39fae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(91), np.int64(18))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demog_df['anchor_age'].max(), demog_df['anchor_age'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf9c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def map_race(race):\n",
    "    if pd.isna(race):\n",
    "        return 'Unknown or Not Reported'\n",
    "    \n",
    "    race = race.upper()\n",
    "    \n",
    "    if 'HISPANIC' in race or 'LATINO' in race or 'SOUTH AMERICAN' in race:\n",
    "        return 'Hispanic or Latino'\n",
    "    elif 'WHITE' in race:\n",
    "        return 'White'\n",
    "    elif 'BLACK' in race or 'AFRICAN' in race:\n",
    "        return 'Black or African American'\n",
    "    elif 'ASIAN' in race:\n",
    "        return 'Asian'\n",
    "    elif 'PACIFIC ISLANDER' in race or 'NATIVE HAWAIIAN' in race:\n",
    "        return 'Native Hawaiian or Other Pacific Islander'\n",
    "    elif 'AMERICAN INDIAN' in race or 'ALASKA NATIVE' in race:\n",
    "        return 'American Indian or Alaska Native'\n",
    "    elif 'DECLINED' in race or 'UNABLE' in race or 'UNKNOWN' in race:\n",
    "        return 'Unknown or Not Reported'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "le = LabelEncoder()\n",
    "demog_df['race_grouped'] = demog_df['race'].apply(map_race)  # apply your earlier grouping\n",
    "demog_df['race_target'] = le.fit_transform(demog_df['race_grouped'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22363332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ages: [57 58 60 72 59 73 75 74 41 61 65 45 71 78 24 50 77 63 69 91 44 42 76 84\n",
      " 56 67 55 80 46 68 47 32 53 33 52 48 30 85 66 83 87 64 81 36 26 79 28 43\n",
      " 70 27 62 25 49 54 89 21 20 82 34 51 40 29 31 86 38 23 88 39 35 22 37 18\n",
      " 19]\n",
      "Unique races: ['HISPANIC/LATINO - GUATEMALAN' 'WHITE' 'BLACK/AFRICAN AMERICAN' 'OTHER'\n",
      " 'ASIAN - CHINESE' 'ASIAN - SOUTH EAST ASIAN' 'ASIAN' 'UNKNOWN'\n",
      " 'WHITE - OTHER EUROPEAN' 'UNABLE TO OBTAIN' 'PATIENT DECLINED TO ANSWER'\n",
      " 'WHITE - RUSSIAN' 'SOUTH AMERICAN' 'WHITE - BRAZILIAN'\n",
      " 'HISPANIC/LATINO - DOMINICAN' 'BLACK/AFRICAN' 'PORTUGUESE'\n",
      " 'HISPANIC/LATINO - PUERTO RICAN' 'BLACK/CAPE VERDEAN'\n",
      " 'HISPANIC/LATINO - HONDURAN' 'HISPANIC/LATINO - CENTRAL AMERICAN'\n",
      " 'BLACK/CARIBBEAN ISLAND' 'ASIAN - ASIAN INDIAN'\n",
      " 'WHITE - EASTERN EUROPEAN' 'HISPANIC/LATINO - COLUMBIAN'\n",
      " 'HISPANIC/LATINO - SALVADORAN' 'HISPANIC/LATINO - CUBAN'\n",
      " 'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER' 'ASIAN - KOREAN'\n",
      " 'HISPANIC/LATINO - MEXICAN' 'AMERICAN INDIAN/ALASKA NATIVE']\n"
     ]
    }
   ],
   "source": [
    "# unique ages and races\n",
    "print(\"Unique ages:\", final_df['anchor_age'].unique())\n",
    "print(\"Unique races:\", final_df['race'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2b4217",
   "metadata": {},
   "source": [
    "##### Fetching labevents data prior `7` or `14` days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59e2632e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>itemid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>target</th>\n",
       "      <th>gender</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10010231</td>\n",
       "      <td>29368887</td>\n",
       "      <td>51233</td>\n",
       "      <td>2118-01-15 17:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2118-01-20 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10010231</td>\n",
       "      <td>29368887</td>\n",
       "      <td>51233</td>\n",
       "      <td>2118-01-15 17:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2118-01-20 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10010231</td>\n",
       "      <td>29368887</td>\n",
       "      <td>51233</td>\n",
       "      <td>2118-01-15 17:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2118-01-20 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10010231</td>\n",
       "      <td>21586397</td>\n",
       "      <td>51678</td>\n",
       "      <td>2117-12-19 06:20:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2117-12-23 16:51:00</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10010231</td>\n",
       "      <td>21586397</td>\n",
       "      <td>51678</td>\n",
       "      <td>2117-12-19 06:20:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2117-12-23 16:51:00</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  itemid           charttime  valuenum  \\\n",
       "0    10010231  29368887   51233 2118-01-15 17:45:00       NaN   \n",
       "1    10010231  29368887   51233 2118-01-15 17:45:00       NaN   \n",
       "2    10010231  29368887   51233 2118-01-15 17:45:00       NaN   \n",
       "3    10010231  21586397   51678 2117-12-19 06:20:00       6.0   \n",
       "4    10010231  21586397   51678 2117-12-19 06:20:00       6.0   \n",
       "\n",
       "            dischtime  target gender  anchor_age                          race  \n",
       "0 2118-01-20 14:00:00       1      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "1 2118-01-20 14:00:00       1      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "2 2118-01-20 14:00:00       1      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "3 2117-12-23 16:51:00       1      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "4 2117-12-23 16:51:00       1      M          57  HISPANIC/LATINO - GUATEMALAN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_parquet = pd.read_parquet(\"../dataset/raw/final_lab_events_7_days.parquet\")\n",
    "raw_parquet.head(5)  # Display the first 5 rows of the raw Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c260e3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10537677"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_parquet)  # Display the number of rows in the raw Parquet file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dcebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get all unique patient IDs\n",
    "patient_ids = pd.read_sql(\"SELECT DISTINCT subject_id FROM public.temp_cohort ORDER BY subject_id\", engine)\n",
    "\n",
    "lab_df = pd.DataFrame()\n",
    "\n",
    "# Process in patient batches\n",
    "batch_size = 100\n",
    "for i in range(0, len(patient_ids), batch_size):\n",
    "    batch = patient_ids.iloc[i:i+batch_size]\n",
    "    batch_list = tuple(batch['subject_id'])\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            le.subject_id, \n",
    "            le.hadm_id, \n",
    "            le.itemid, \n",
    "            le.charttime, \n",
    "            le.valuenum,\n",
    "            tc.dischtime,\n",
    "            tc.target\n",
    "        FROM mimiciv_hosp.labevents le\n",
    "        JOIN public.temp_cohort tc\n",
    "          ON le.subject_id = tc.subject_id\n",
    "         AND le.hadm_id = tc.hadm_id\n",
    "        WHERE le.charttime BETWEEN (tc.dischtime - INTERVAL '7 days') AND tc.dischtime\n",
    "        AND le.subject_id IN {batch_list}\n",
    "    \"\"\"\n",
    "    \n",
    "    chunk = pd.read_sql(query, engine)\n",
    "    # Process your chunk\n",
    "    lab_df = pd.concat([lab_df, chunk], ignore_index=True)\n",
    "# Reset index after concat\n",
    "lab_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5118bd",
   "metadata": {},
   "source": [
    "# Pre-processing for tabular data\n",
    "\n",
    "### Aggregating on an `hourly` basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8ac671b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10537677"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "patient_data_df = pl.read_parquet(\"../dataset/raw/lab_events_7_days_prior.parquet\")\n",
    "len(patient_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a3fd1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def assign_time_bin(hours_before_discharge, window_hours=6):\n",
    "    \"\"\"Assign records to fixed time bins (e.g., 0-6h, 6-12h).\n",
    "    Example: For a 6-hour window:\n",
    "        0.5h → bin 0, 6.1h → bin 6, 23h → bin 18\n",
    "    \"\"\"\n",
    "    return (np.floor(hours_before_discharge / window_hours) * window_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b515bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 290346 records within 12-hour window...\n",
      "Created numeric features: (3076, 1459)\n",
      "Created binary features: (3099, 2036)\n",
      "Filtered down to 290346 rows from 3518649\n",
      "Number of unique hadm_ids: 3099\n"
     ]
    }
   ],
   "source": [
    "# Create a copy and convert timestamps\n",
    "new_df = patient_data_df.copy()\n",
    "new_df[\"charttime\"] = pd.to_datetime(new_df[\"charttime\"])\n",
    "new_df[\"dischtime\"] = pd.to_datetime(new_df[\"dischtime\"])\n",
    "\n",
    "# Calculate hours before discharge\n",
    "new_df[\"hours_before_discharge\"] = (new_df[\"dischtime\"] - new_df[\"charttime\"]).dt.total_seconds() / 3600\n",
    "\n",
    "# Filter to 12-hour window (0 to 12 hours inclusive)\n",
    "new_df_filtered = new_df[\n",
    "    (new_df[\"hours_before_discharge\"] >= 0) & (new_df[\"hours_before_discharge\"] <= 12)\n",
    "].copy()\n",
    "\n",
    "print(f\"Processing {len(new_df_filtered)} records within 12-hour window...\")\n",
    "\n",
    "# Create hourly bins (1-12)\n",
    "new_df_filtered[\"hour_bin\"] = (np.floor(new_df_filtered[\"hours_before_discharge\"]) + 1).astype(int)\n",
    "new_df_filtered[\"hour_bin\"] = new_df_filtered[\"hour_bin\"].clip(upper=12)  # Cap at 12\n",
    "\n",
    "# Create feature_id with hour bin\n",
    "new_df_filtered[\"feature_id\"] = (\n",
    "    \"itemid_\" + \n",
    "    new_df_filtered[\"itemid\"].astype(str) + \n",
    "    \"_last_\" + \n",
    "    new_df_filtered[\"hour_bin\"].astype(str) + \n",
    "    \"h\"\n",
    ")\n",
    "\n",
    "# Pivot numeric features (mean aggregation)\n",
    "numeric_pivot = new_df_filtered.pivot_table(\n",
    "    index=\"hadm_id\",\n",
    "    columns=\"feature_id\",\n",
    "    values=\"valuenum\",\n",
    "    aggfunc=\"mean\",\n",
    "    # fill_value=np.nan,\n",
    ")\n",
    "# Pivot binary features (existence indicator)\n",
    "new_df_filtered[\"has_measurement\"] = 1\n",
    "binary_pivot = new_df_filtered.pivot_table(\n",
    "    index=\"hadm_id\",\n",
    "    columns=\"feature_id\",\n",
    "    values=\"has_measurement\",\n",
    "    aggfunc=\"max\",  # 1 if any measurement exists\n",
    "    fill_value=0,\n",
    ")\n",
    "binary_pivot.columns = [col + \"_measured\" for col in binary_pivot.columns]\n",
    "\n",
    "# combined_features = numeric_filled.join(targets).reset_index()\n",
    "\n",
    "# Get targets\n",
    "targets = new_df_filtered[[\"hadm_id\", \"target\"]].drop_duplicates().set_index(\"hadm_id\")\n",
    "\n",
    "# Combine features with targets (NO forward/backward fill)\n",
    "numeric_features = numeric_filled.join(targets).reset_index()\n",
    "binary_features = binary_pivot.join(targets).reset_index()\n",
    "\n",
    "print(f\"Created numeric features: {numeric_features.shape}\")\n",
    "print(f\"Created binary features: {binary_features.shape}\")\n",
    "print(f\"Filtered down to {len(new_df_filtered)} rows from {len(new_df)}\")\n",
    "print(f\"Number of unique hadm_ids: {new_df_filtered['hadm_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0a9b7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368        9\n",
       "369        9\n",
       "370        9\n",
       "371        9\n",
       "372        9\n",
       "          ..\n",
       "3518463    5\n",
       "3518464    5\n",
       "3518465    5\n",
       "3518466    5\n",
       "3518467    5\n",
       "Name: hours_before_discharge, Length: 290346, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.floor(new_df_filtered[\"hours_before_discharge\"])).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0fe38a",
   "metadata": {},
   "source": [
    "# Preprocessing for Temporal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d128b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10537677"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "patient_data_df = pl.read_parquet(\"../dataset/raw/lab_events_7_days_prior.parquet\")\n",
    "len(patient_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02fea5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>subject_id</th><th>hadm_id</th><th>itemid</th><th>charttime</th><th>valuenum</th><th>dischtime</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>datetime[ns]</td><td>f64</td><td>datetime[ns]</td></tr></thead><tbody><tr><td>16880728</td><td>28323062</td><td>51237</td><td>2173-05-11 05:39:00</td><td>1.0</td><td>2173-05-12 13:55:00</td></tr><tr><td>14761827</td><td>22027366</td><td>51678</td><td>2150-02-01 05:15:00</td><td>9.0</td><td>2150-02-01 12:40:00</td></tr><tr><td>18792281</td><td>28698097</td><td>50868</td><td>2182-02-06 06:24:00</td><td>14.0</td><td>2182-02-06 18:30:00</td></tr><tr><td>10441608</td><td>28877350</td><td>50971</td><td>2180-04-17 00:16:00</td><td>3.9</td><td>2180-04-18 21:00:00</td></tr><tr><td>15235658</td><td>25509693</td><td>50878</td><td>2129-10-08 05:07:00</td><td>21.0</td><td>2129-10-14 14:00:00</td></tr><tr><td>18373372</td><td>25329845</td><td>51254</td><td>2137-11-24 06:10:00</td><td>5.0</td><td>2137-11-25 14:33:00</td></tr><tr><td>13513262</td><td>24857347</td><td>50960</td><td>2178-11-14 00:00:00</td><td>2.1</td><td>2178-11-16 17:12:00</td></tr><tr><td>13866704</td><td>21640111</td><td>50878</td><td>2162-11-01 05:47:00</td><td>82.0</td><td>2162-11-05 17:32:00</td></tr><tr><td>10822967</td><td>21555795</td><td>51491</td><td>2111-01-31 04:00:00</td><td>6.5</td><td>2111-02-03 13:56:00</td></tr><tr><td>14922593</td><td>26124113</td><td>51487</td><td>2143-12-23 08:20:00</td><td>null</td><td>2143-12-25 21:15:00</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 6)\n",
       "┌────────────┬──────────┬────────┬─────────────────────┬──────────┬─────────────────────┐\n",
       "│ subject_id ┆ hadm_id  ┆ itemid ┆ charttime           ┆ valuenum ┆ dischtime           │\n",
       "│ ---        ┆ ---      ┆ ---    ┆ ---                 ┆ ---      ┆ ---                 │\n",
       "│ i64        ┆ i64      ┆ i64    ┆ datetime[ns]        ┆ f64      ┆ datetime[ns]        │\n",
       "╞════════════╪══════════╪════════╪═════════════════════╪══════════╪═════════════════════╡\n",
       "│ 16880728   ┆ 28323062 ┆ 51237  ┆ 2173-05-11 05:39:00 ┆ 1.0      ┆ 2173-05-12 13:55:00 │\n",
       "│ 14761827   ┆ 22027366 ┆ 51678  ┆ 2150-02-01 05:15:00 ┆ 9.0      ┆ 2150-02-01 12:40:00 │\n",
       "│ 18792281   ┆ 28698097 ┆ 50868  ┆ 2182-02-06 06:24:00 ┆ 14.0     ┆ 2182-02-06 18:30:00 │\n",
       "│ 10441608   ┆ 28877350 ┆ 50971  ┆ 2180-04-17 00:16:00 ┆ 3.9      ┆ 2180-04-18 21:00:00 │\n",
       "│ 15235658   ┆ 25509693 ┆ 50878  ┆ 2129-10-08 05:07:00 ┆ 21.0     ┆ 2129-10-14 14:00:00 │\n",
       "│ 18373372   ┆ 25329845 ┆ 51254  ┆ 2137-11-24 06:10:00 ┆ 5.0      ┆ 2137-11-25 14:33:00 │\n",
       "│ 13513262   ┆ 24857347 ┆ 50960  ┆ 2178-11-14 00:00:00 ┆ 2.1      ┆ 2178-11-16 17:12:00 │\n",
       "│ 13866704   ┆ 21640111 ┆ 50878  ┆ 2162-11-01 05:47:00 ┆ 82.0     ┆ 2162-11-05 17:32:00 │\n",
       "│ 10822967   ┆ 21555795 ┆ 51491  ┆ 2111-01-31 04:00:00 ┆ 6.5      ┆ 2111-02-03 13:56:00 │\n",
       "│ 14922593   ┆ 26124113 ┆ 51487  ┆ 2143-12-23 08:20:00 ┆ null     ┆ 2143-12-25 21:15:00 │\n",
       "└────────────┴──────────┴────────┴─────────────────────┴──────────┴─────────────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = patient_data_df.clone()\n",
    "temp_df = temp_df.drop([\"race\", \"gender\", \"anchor_age\", \"target\"])\n",
    "temp_df = temp_df.unique(subset=[\"subject_id\", \"hadm_id\", \"itemid\", \"charttime\"])\n",
    "temp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67f43389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def assign_time_bin(hours_before_discharge, window_hours=6):\n",
    "    \"\"\"Assign records to fixed time bins (e.g., 0-6h, 6-12h).\n",
    "    Example: For a 6-hour window:\n",
    "        0.5h → bin 0, 6.1h → bin 6, 23h → bin 18\n",
    "    \"\"\"\n",
    "    return (np.floor(hours_before_discharge / window_hours) * window_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bdd33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_window_size = 12\n",
    "# aggregating all lab events per admission into a single row with many columns\n",
    "window_size = 7\n",
    "filtering_hours = window_size * 24  # convert days to hours\n",
    "\n",
    "temp_df.loc[:, \"days_before_discharge\"] = (\n",
    "    temp_df[\"dischtime\"] - temp_df[\"charttime\"]\n",
    ").dt.total_seconds() / 3600  # convert to hours\n",
    "\n",
    "temp_df = temp_df[\n",
    "    (temp_df[\"days_before_discharge\"] >= 0)\n",
    "    & (temp_df[\"days_before_discharge\"] < filtering_hours)\n",
    "].copy()\n",
    "\n",
    "temp_df.loc[:, \"time_bin\"] = assign_time_bin(\n",
    "    temp_df[\"days_before_discharge\"], aggregation_window_size\n",
    ")\n",
    "# Convert time_bin to string for feature_id\n",
    "temp_df.loc[:, \"feature_id\"] = (\n",
    "    \"itemid_\"\n",
    "    + temp_df[\"itemid\"].astype(str)\n",
    "    + \"_last_\"\n",
    "    + temp_df[\"time_bin\"].astype(str)\n",
    "    + \"_hours_prior\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d537c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_x_m_d(df, max_window_days=7):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \"\"\"\n",
    "    Convert DataFrame to GRU-D inputs (x, masking, delta), using raw `itemid` as indices.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns ['subject_id', 'hadm_id', 'itemid', 'charttime', 'valuenum', 'dischtime'].\n",
    "        max_window_days: Maximum days before discharge to include.\n",
    "    \n",
    "    Returns:\n",
    "        x: Feature matrix of shape (n_features, n_timesteps).\n",
    "        masking: Binary mask of observed values (same shape as x).\n",
    "        delta: Time gaps since last observation (same shape as x).\n",
    "        timestamps: Hours since discharge for each timestep.\n",
    "        ids: DataFrame with ['subject_id', 'hadm_id'] for each timestep.\n",
    "    \"\"\"\n",
    "    # polars df to pandas df\n",
    "    # if isinstance(df, pl.DataFrame):\n",
    "    #     df = df.to_pandas()\n",
    "        \n",
    "    # --- 1. Preprocess Timestamps ---\n",
    "    df = df.with_columns(\n",
    "        ((pl.col(\"dischtime\") - pl.col(\"charttime\")).dt.total_seconds() / 3600)\n",
    "        .alias(\"hours_since_discharge\")\n",
    "    )\n",
    "\n",
    "    df = df.filter(\n",
    "        (pl.col(\"hours_since_discharge\") >= 0)\n",
    "        & (pl.col(\"hours_since_discharge\") <= max_window_days * 24)\n",
    "    ) # Truncate to window\n",
    "    \n",
    "    # --- 2. Group by Patient and Time ---\n",
    "    grouped = df.sort(by=[\"subject_id\", \"hadm_id\", \"charttime\"]) \\\n",
    "            .group_by([\"subject_id\", \"hadm_id\", \"charttime\"], maintain_order=False)\n",
    "\n",
    "    grouped_df = grouped.agg([\n",
    "        pl.len().alias(\"group_size\")\n",
    "    ])\n",
    "\n",
    "    n_timesteps = grouped_df.height\n",
    "\n",
    "\n",
    "    # --- 3. Initialize Arrays ---\n",
    "    n_features = df[\"itemid\"].max() + 1  # Assumes itemids start at 0\n",
    "    x = np.zeros((n_features, n_timesteps))\n",
    "    masking = np.zeros_like(x)\n",
    "    timestamps = np.zeros(n_timesteps)\n",
    "    ids = []\n",
    "    \n",
    "    # --- 4. Populate x, masking, and timestamps ---\n",
    "    for i, ((subj_id, adm_id, time), group) in enumerate(grouped):\n",
    "        timestamps[i] = (time - group[\"dischtime\"][0]).total_seconds() / 3600\n",
    "        ids.append({\"subject_id\": subj_id, \"hadm_id\": adm_id})\n",
    "        for row in group.iter_rows(named=True):\n",
    "            x[row[\"itemid\"], i] = row[\"valuenum\"]\n",
    "            masking[row[\"itemid\"], i] = 1\n",
    "\n",
    "    \n",
    "    # --- 5. Calculate delta ---\n",
    "    delta = np.zeros_like(x)\n",
    "    for i in range(1, n_timesteps):\n",
    "        time_gap = timestamps[i] - timestamps[i-1]\n",
    "        delta[:, i] = np.where(\n",
    "            masking[:, i-1] == 0,\n",
    "            time_gap + delta[:, i-1],  # Accumulate if previous value was missing\n",
    "            time_gap                   # Else use actual time gap\n",
    "        )\n",
    "    \n",
    "    return x, masking, delta, timestamps, pd.DataFrame(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b18475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (53175, 8550)\n",
      "masking shape: (53175, 8550)\n",
      "delta shape: (53175, 8550)\n",
      "Timestamps (hours before discharge): [-162.         -103.66666667  -53.75       ...  -29.78333333  -86.76666667\n",
      " -155.11666667]\n"
     ]
    }
   ],
   "source": [
    "x, masking, delta, timestamps, ids = df_to_x_m_d(temp_df.head(10000), max_window_days=7)\n",
    "\n",
    "print(\"x shape:\", x.shape)          # (max_itemid + 1, n_timesteps)\n",
    "print(\"masking shape:\", masking.shape)  # Same as x\n",
    "print(\"delta shape:\", delta.shape)    # Same as x\n",
    "print(\"Timestamps (hours before discharge):\", timestamps)\n",
    "# print(\"Patient IDs:\", ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0131120e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-162.        , -103.66666667,  -53.75      , ...,  -29.78333333,\n",
       "        -86.76666667, -155.11666667], shape=(8550,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a4840d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
