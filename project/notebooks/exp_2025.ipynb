{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a064a422",
   "metadata": {},
   "source": [
    "## Show the tables in schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ec9e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema: mimiciv_icu\n",
      "['caregiver', 'chartevents', 'datetimeevents', 'd_items', 'icustays', 'ingredientevents', 'inputevents', 'outputevents', 'procedureevents']\n",
      "Schema: mimiciv_hosp\n",
      "['admissions', 'd_hcpcs', 'diagnoses_icd', 'd_icd_diagnoses', 'd_icd_procedures', 'd_labitems', 'drgcodes', 'emar_detail', 'emar', 'hcpcsevents', 'labevents', 'microbiologyevents', 'omr', 'patients', 'pharmacy', 'poe_detail', 'poe', 'prescriptions', 'procedures_icd', 'provider', 'services', 'transfers']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))  # adding the parent directory of 'notebooks' to sys.path\n",
    "from utils import Database\n",
    "engine = Database()\n",
    "schema_list = [\"mimiciv_icu\", \"mimiciv_hosp\"]\n",
    "for schema in schema_list:\n",
    "    print(f\"Schema: {schema}\")\n",
    "    tables = Database.show_tables_in_schema(engine, schema)\n",
    "    print(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062ade55",
   "metadata": {},
   "source": [
    "## Load tables into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce24add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "admission_db = Database()\n",
    "chunk_size = 100000\n",
    "admission_df = admission_db.read_table_to_df(\n",
    "    table_name=\"admissions\", \n",
    "    schema_name=\"mimiciv_hosp\", \n",
    "    limit=chunk_size,\n",
    "    # order_by=\"admittime\",\n",
    ")\n",
    "\n",
    "labevents_df = admission_db.read_table_to_df(\n",
    "    table_name=\"labevents\", \n",
    "    schema_name=\"mimiciv_hosp\", \n",
    "    limit=chunk_size,\n",
    ")\n",
    "\n",
    "# datetime conversions\n",
    "admission_df['admittime'] = pd.to_datetime(admission_df['admittime'], errors='coerce')\n",
    "admission_df['dischtime'] = pd.to_datetime(admission_df['dischtime'], errors='coerce')\n",
    "labevents_df['charttime'] = pd.to_datetime(labevents_df['charttime'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d72f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data_df = pd.merge(\n",
    "    labevents_df,\n",
    "    admission_df[[\"subject_id\", \"hadm_id\", \"admittime\", \"dischtime\"]],\n",
    "    on=[\"subject_id\", \"hadm_id\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "# Filter labevents to only include those within the admission time frame\n",
    "patient_data_df = patient_data_df[\n",
    "    (patient_data_df.charttime >= patient_data_df.admittime)\n",
    "    & (patient_data_df.charttime <= patient_data_df.dischtime)\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0274c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data_df[\"hours_since_admit\"] = (\n",
    "    patient_data_df[\"charttime\"] - patient_data_df[\"admittime\"]\n",
    ").dt.total_seconds() / 3600\n",
    "# patient_data_df['hours_since_discht'] = (\n",
    "#     patient_data_df['dischtime'] - patient_data_df['charttime']\n",
    "# ).dt.total_seconds() / 3600\n",
    "\n",
    "# valuenum is the float value of the 'value' column\n",
    "patient_data_df = patient_data_df[\n",
    "    [\n",
    "        \"subject_id\",\n",
    "        \"hadm_id\",\n",
    "        \"admittime\",\n",
    "        \"dischtime\",\n",
    "        \"hours_since_admit\",\n",
    "        \"itemid\",\n",
    "        \"valuenum\",\n",
    "        \"charttime\",\n",
    "    ]\n",
    "]\n",
    "patient_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727cba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe4822",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_patient_data_df = patient_data_df.pivot_table(\n",
    "    index=['subject_id', 'hadm_id', 'hours_since_admit'],\n",
    "    columns='itemid',\n",
    "    values='valuenum',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a29585",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_patient_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e004ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_patient_data_df = patient_data_df.pivot_table(\n",
    "    index=['subject_id', 'hadm_id', 'hours_since_admit'],\n",
    "    columns='itemid',\n",
    "    values='valuenum',\n",
    "    aggfunc=lambda x: 1 if not pd.isna(x).any() else 0\n",
    ")\n",
    "masked_patient_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70049061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each itemid, compute time since last observation\n",
    "deltas = {}\n",
    "itemids = patient_data_df['itemid'].unique()\n",
    "for item in itemids:\n",
    "    item_df = patient_data_df[patient_data_df['itemid'] == item].sort_values('hours_since_admit')\n",
    "    item_df['delta'] = item_df['hours_since_admit'].diff().fillna(0)\n",
    "    deltas[item] = item_df.set_index('hours_since_admit')['delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b2b002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "526cc2c0",
   "metadata": {},
   "source": [
    "# Getting all `labevents` data and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e76c84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Database connection parameters\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "url = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(url)\n",
    "conn = engine.connect()\n",
    "cursor = conn.connection.cursor()\n",
    "# Create the table temporarily in the database\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TEMP TABLE temp_cohort (\n",
    "        subject_id INT,\n",
    "        hadm_id INT,\n",
    "        admittime TIMESTAMP,\n",
    "        dischtime TIMESTAMP,\n",
    "        target  INT\n",
    "    );\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c650a9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from psycopg2.extras import execute_values\n",
    "cohort_df = pd.read_csv('../assets/cohort1_target.csv')\n",
    "cohort_df['admittime'] = pd.to_datetime(cohort_df['admittime'], errors='coerce')\n",
    "cohort_df['dischtime'] = pd.to_datetime(cohort_df['dischtime'], errors='coerce')\n",
    "\n",
    "# Insert the data from the DataFrame into the temporary table\n",
    "cohort_df.to_sql(\"temp_cohort\", engine, schema=\"public\", index=False, if_exists=\"replace\")\n",
    "\n",
    "values = list(cohort_df.itertuples(index=False, name=None))\n",
    "execute_values(cursor,\n",
    "    \"INSERT INTO temp_cohort (subject_id, hadm_id, admittime, dischtime, target) VALUES %s\",\n",
    "    values\n",
    ")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a7773a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.errors.ConfigurationLimitExceeded) temporary file size exceeds temp_file_limit (2097152kB)\n\n[SQL: \nSELECT \n    le.subject_id, \n    le.hadm_id, \n    le.itemid, \n    le.charttime, \n    le.valuenum,\n    tc.dischtime,\n    tc.target\nFROM mimiciv_hosp.labevents le\nJOIN public.temp_cohort tc\n  ON le.subject_id = tc.subject_id\n AND le.hadm_id = tc.hadm_id\n WHERE le.charttime BETWEEN (tc.dischtime - INTERVAL '14 days') AND tc.dischtime;\n]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConfigurationLimitExceeded\u001b[39m                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/BioInformatics/informative-missingness/.myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1964\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1963\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1965\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1966\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/BioInformatics/informative-missingness/.myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:945\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mConfigurationLimitExceeded\u001b[39m: temporary file size exceeds temp_file_limit (2097152kB)\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      1\u001b[39m query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33mSELECT \u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33m    le.subject_id, \u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[33m WHERE le.charttime BETWEEN (tc.dischtime - INTERVAL \u001b[39m\u001b[33m'\u001b[39m\u001b[33m14 days\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) AND tc.dischtime;\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# WHERE le.charttime BETWEEN (tc.dischtime - INTERVAL '7 days') AND tc.dischtime;\u001b[39;00m\n\u001b[32m     17\u001b[39m \n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Run query in chunks\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m lab_chunks = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Combine all chunks into a single DataFrame\u001b[39;00m\n\u001b[32m     22\u001b[39m lab_df = pd.concat(chunk \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m lab_chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/BioInformatics/informative-missingness/.myenv/lib/python3.11/site-packages/pandas/io/sql.py:734\u001b[39m, in \u001b[36mread_sql\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[39m\n\u001b[32m    724\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql.read_table(\n\u001b[32m    725\u001b[39m         sql,\n\u001b[32m    726\u001b[39m         index_col=index_col,\n\u001b[32m   (...)\u001b[39m\u001b[32m    731\u001b[39m         dtype_backend=dtype_backend,\n\u001b[32m    732\u001b[39m     )\n\u001b[32m    733\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/BioInformatics/informative-missingness/.myenv/lib/python3.11/site-packages/pandas/io/sql.py:1836\u001b[39m, in \u001b[36mSQLDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   1780\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1781\u001b[39m     sql: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1788\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1789\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m   1790\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1791\u001b[39m \u001b[33;03m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[32m   1792\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1834\u001b[39m \n\u001b[32m   1835\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1836\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1837\u001b[39m     columns = result.keys()\n\u001b[32m   1839\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/BioInformatics/informative-missingness/.myenv/lib/python3.11/site-packages/pandas/io/sql.py:1659\u001b[39m, in \u001b[36mSQLDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   1657\u001b[39m args = [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[32m   1658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1659\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_driver_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1660\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.con.execute(sql, *args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/BioInformatics/informative-missingness/.myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1776\u001b[39m, in \u001b[36mConnection.exec_driver_sql\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1771\u001b[39m execution_options = \u001b[38;5;28mself\u001b[39m._execution_options.merge_with(\n\u001b[32m   1772\u001b[39m     execution_options\n\u001b[32m   1773\u001b[39m )\n\u001b[32m   1775\u001b[39m dialect = \u001b[38;5;28mself\u001b[39m.dialect\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1777\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1778\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_statement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1779\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1780\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1782\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/BioInformatics/informative-missingness/.myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1843\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exec_insertmany_context(dialect, context)\n\u001b[32m   1842\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[32m   1845\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/BioInformatics/informative-missingness/.myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1983\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1980\u001b[39m     result = context._setup_result_proxy()\n\u001b[32m   1982\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1983\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1984\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/BioInformatics/informative-missingness/.myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2352\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[39m\n\u001b[32m   2350\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[32m   2351\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2352\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2353\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2354\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/BioInformatics/informative-missingness/.myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1964\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1962\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1963\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1965\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1966\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n\u001b[32m   1969\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_cursor_execute(\n\u001b[32m   1970\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1971\u001b[39m         cursor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1975\u001b[39m         context.executemany,\n\u001b[32m   1976\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/BioInformatics/informative-missingness/.myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:945\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOperationalError\u001b[39m: (psycopg2.errors.ConfigurationLimitExceeded) temporary file size exceeds temp_file_limit (2097152kB)\n\n[SQL: \nSELECT \n    le.subject_id, \n    le.hadm_id, \n    le.itemid, \n    le.charttime, \n    le.valuenum,\n    tc.dischtime,\n    tc.target\nFROM mimiciv_hosp.labevents le\nJOIN public.temp_cohort tc\n  ON le.subject_id = tc.subject_id\n AND le.hadm_id = tc.hadm_id\n WHERE le.charttime BETWEEN (tc.dischtime - INTERVAL '14 days') AND tc.dischtime;\n]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    le.subject_id, \n",
    "    le.hadm_id, \n",
    "    le.itemid, \n",
    "    le.charttime, \n",
    "    le.valuenum,\n",
    "    tc.dischtime,\n",
    "    tc.target\n",
    "FROM mimiciv_hosp.labevents le\n",
    "JOIN public.temp_cohort tc\n",
    "  ON le.subject_id = tc.subject_id\n",
    " AND le.hadm_id = tc.hadm_id\n",
    " WHERE le.charttime BETWEEN (tc.dischtime - INTERVAL '14 days') AND tc.dischtime;\n",
    "\"\"\"\n",
    "# WHERE le.charttime BETWEEN (tc.dischtime - INTERVAL '7 days') AND tc.dischtime;\n",
    "\n",
    "# Run query in chunks\n",
    "lab_chunks = pd.read_sql(query, engine, chunksize=1000)\n",
    "\n",
    "# Combine all chunks into a single DataFrame\n",
    "lab_df = pd.concat(chunk for chunk in lab_chunks)\n",
    "\n",
    "# Reset index after concat\n",
    "lab_df.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3347cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to lab_events_14_days_prior.parquet\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    lab_df.to_parquet(\"../dataset/lab_events_14_days_prior.parquet\", index=False)\n",
    "    # lab_df.to_parquet(\"../dataset/lab_events_7_days_prior.parquet\", index=False)\n",
    "    print(\"Data successfully written to lab_events_14_days_prior.parquet\")\n",
    "except Exception as e:\n",
    "    lab_df.to_parquet(\"lab_events_14_days_prior.parquet\", index=False)\n",
    "    print(f\"File written to current directory: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d7846fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>itemid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10010231</td>\n",
       "      <td>29368887</td>\n",
       "      <td>51233</td>\n",
       "      <td>2118-01-15 17:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2118-01-20 14:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10010231</td>\n",
       "      <td>21586397</td>\n",
       "      <td>51678</td>\n",
       "      <td>2117-12-19 06:20:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2117-12-23 16:51:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10010231</td>\n",
       "      <td>21586397</td>\n",
       "      <td>50861</td>\n",
       "      <td>2117-12-18 10:12:00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2117-12-23 16:51:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10010231</td>\n",
       "      <td>21586397</td>\n",
       "      <td>50862</td>\n",
       "      <td>2117-12-18 10:12:00</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2117-12-23 16:51:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10010231</td>\n",
       "      <td>21586397</td>\n",
       "      <td>50863</td>\n",
       "      <td>2117-12-18 10:12:00</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2117-12-23 16:51:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  itemid           charttime  valuenum  \\\n",
       "0    10010231  29368887   51233 2118-01-15 17:45:00       NaN   \n",
       "1    10010231  21586397   51678 2117-12-19 06:20:00       6.0   \n",
       "2    10010231  21586397   50861 2117-12-18 10:12:00      22.0   \n",
       "3    10010231  21586397   50862 2117-12-18 10:12:00       3.9   \n",
       "4    10010231  21586397   50863 2117-12-18 10:12:00      68.0   \n",
       "\n",
       "            dischtime  target  \n",
       "0 2118-01-20 14:00:00       1  \n",
       "1 2117-12-23 16:51:00       1  \n",
       "2 2117-12-23 16:51:00       1  \n",
       "3 2117-12-23 16:51:00       1  \n",
       "4 2117-12-23 16:51:00       1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "595049aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4859673"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lab_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5118bd",
   "metadata": {},
   "source": [
    "# Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18517567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a921b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>itemid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10010231</td>\n",
       "      <td>29368887</td>\n",
       "      <td>51233</td>\n",
       "      <td>2118-01-15 17:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2118-01-20 14:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10022373</td>\n",
       "      <td>27450651</td>\n",
       "      <td>50878</td>\n",
       "      <td>2150-06-03 05:49:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2150-06-06 14:30:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10022373</td>\n",
       "      <td>27450651</td>\n",
       "      <td>51221</td>\n",
       "      <td>2150-05-31 06:00:00</td>\n",
       "      <td>25.9</td>\n",
       "      <td>2150-06-06 14:30:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10022373</td>\n",
       "      <td>27450651</td>\n",
       "      <td>51222</td>\n",
       "      <td>2150-05-31 06:00:00</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2150-06-06 14:30:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10022373</td>\n",
       "      <td>27450651</td>\n",
       "      <td>51248</td>\n",
       "      <td>2150-05-31 06:00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2150-06-06 14:30:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  itemid           charttime  valuenum  \\\n",
       "0    10010231  29368887   51233 2118-01-15 17:45:00       NaN   \n",
       "1    10022373  27450651   50878 2150-06-03 05:49:00      38.0   \n",
       "2    10022373  27450651   51221 2150-05-31 06:00:00      25.9   \n",
       "3    10022373  27450651   51222 2150-05-31 06:00:00       8.3   \n",
       "4    10022373  27450651   51248 2150-05-31 06:00:00      31.0   \n",
       "\n",
       "            dischtime  target  \n",
       "0 2118-01-20 14:00:00       1  \n",
       "1 2150-06-06 14:30:00       0  \n",
       "2 2150-06-06 14:30:00       0  \n",
       "3 2150-06-06 14:30:00       0  \n",
       "4 2150-06-06 14:30:00       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data_df = pd.read_parquet(\"../dataset/raw/lab_events_7_days_prior.parquet\")\n",
    "patient_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45634c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3518406 records within 7-day windows...\n",
      "Created numeric features: (4907, 2199)\n",
      "Created binary features: (4908, 3083)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = patient_data_df.copy()\n",
    "df[\"charttime\"] = pd.to_datetime(df[\"charttime\"])\n",
    "df[\"dischtime\"] = pd.to_datetime(df[\"dischtime\"])\n",
    "\n",
    "# Calculate days before discharge\n",
    "df[\"days_before_discharge\"] = (df[\"dischtime\"] - df[\"charttime\"]).dt.days\n",
    "\n",
    "# Filter to 7-day window\n",
    "df_filtered = df[\n",
    "    (df[\"days_before_discharge\"] >= 0) & (df[\"days_before_discharge\"] <= 6)\n",
    "].copy()\n",
    "\n",
    "print(f\"Processing {len(df_filtered)} records within 7-day windows...\")\n",
    "\n",
    "# Create feature identifier combining itemid and day\n",
    "df_filtered[\"feature_id\"] = (\n",
    "    \"itemid_\"\n",
    "    + df_filtered[\"itemid\"].astype(str)\n",
    "    + \"_day_\"\n",
    "    + df_filtered[\"days_before_discharge\"].astype(str)\n",
    ")\n",
    "\n",
    "# NUMERIC FEATURES - Pivot table with mean aggregation\n",
    "numeric_pivot = df_filtered.pivot_table(\n",
    "    index=\"hadm_id\",\n",
    "    columns=\"feature_id\",\n",
    "    values=\"valuenum\",\n",
    "    aggfunc=\"mean\",  # Average multiple measurements per day\n",
    "    fill_value=np.nan,\n",
    ")\n",
    "\n",
    "# BINARY FEATURES - Pivot table indicating if measurement exists\n",
    "# Create binary indicator (1 if any measurement, 0 if none)\n",
    "df_filtered[\"has_measurement\"] = 1\n",
    "binary_pivot = df_filtered.pivot_table(\n",
    "    index=\"hadm_id\",\n",
    "    columns=\"feature_id\",\n",
    "    values=\"has_measurement\",\n",
    "    aggfunc=\"max\",  # Max will be 1 if any measurement exists\n",
    "    fill_value=0,\n",
    ")\n",
    "\n",
    "# Add suffix to distinguish binary features\n",
    "binary_pivot.columns = [col + \"_measured\" for col in binary_pivot.columns]\n",
    "\n",
    "# Get targets for each admission\n",
    "targets = df_filtered[[\"hadm_id\", \"target\"]].drop_duplicates().set_index(\"hadm_id\")\n",
    "\n",
    "# Combine with targets\n",
    "numeric_pivot = numeric_pivot.sort_index(axis=1)\n",
    "numeric_pivot = numeric_pivot.ffill(axis=1).bfill(axis=1)  # Forward and backward fill to handle NaNs\n",
    "\n",
    "numeric_features = numeric_pivot.join(targets).reset_index()\n",
    "binary_features = binary_pivot.join(targets).reset_index()\n",
    "\n",
    "print(f\"Created numeric features: {numeric_features.shape}\")\n",
    "print(f\"Created binary features: {binary_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b491b728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>itemid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10010231</td>\n",
       "      <td>29368887</td>\n",
       "      <td>51233</td>\n",
       "      <td>2118-01-15 17:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2118-01-20 14:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10022373</td>\n",
       "      <td>27450651</td>\n",
       "      <td>50878</td>\n",
       "      <td>2150-06-03 05:49:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2150-06-06 14:30:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10022373</td>\n",
       "      <td>27450651</td>\n",
       "      <td>51221</td>\n",
       "      <td>2150-05-31 06:00:00</td>\n",
       "      <td>25.9</td>\n",
       "      <td>2150-06-06 14:30:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10022373</td>\n",
       "      <td>27450651</td>\n",
       "      <td>51222</td>\n",
       "      <td>2150-05-31 06:00:00</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2150-06-06 14:30:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10022373</td>\n",
       "      <td>27450651</td>\n",
       "      <td>51248</td>\n",
       "      <td>2150-05-31 06:00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2150-06-06 14:30:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  itemid           charttime  valuenum  \\\n",
       "0    10010231  29368887   51233 2118-01-15 17:45:00       NaN   \n",
       "1    10022373  27450651   50878 2150-06-03 05:49:00      38.0   \n",
       "2    10022373  27450651   51221 2150-05-31 06:00:00      25.9   \n",
       "3    10022373  27450651   51222 2150-05-31 06:00:00       8.3   \n",
       "4    10022373  27450651   51248 2150-05-31 06:00:00      31.0   \n",
       "\n",
       "            dischtime  target  \n",
       "0 2118-01-20 14:00:00       1  \n",
       "1 2150-06-06 14:30:00       0  \n",
       "2 2150-06-06 14:30:00       0  \n",
       "3 2150-06-06 14:30:00       0  \n",
       "4 2150-06-06 14:30:00       0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bde48de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>itemid_50801_day_2</th>\n",
       "      <th>itemid_50801_day_6</th>\n",
       "      <th>itemid_50802_day_0</th>\n",
       "      <th>itemid_50802_day_1</th>\n",
       "      <th>itemid_50802_day_2</th>\n",
       "      <th>itemid_50802_day_3</th>\n",
       "      <th>itemid_50802_day_4</th>\n",
       "      <th>itemid_50802_day_5</th>\n",
       "      <th>itemid_50802_day_6</th>\n",
       "      <th>...</th>\n",
       "      <th>itemid_53173_day_4</th>\n",
       "      <th>itemid_53173_day_6</th>\n",
       "      <th>itemid_53174_day_0</th>\n",
       "      <th>itemid_53174_day_1</th>\n",
       "      <th>itemid_53174_day_2</th>\n",
       "      <th>itemid_53174_day_3</th>\n",
       "      <th>itemid_53174_day_4</th>\n",
       "      <th>itemid_53174_day_6</th>\n",
       "      <th>itemid_53180_day_1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20004072</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.85</td>\n",
       "      <td>73.85</td>\n",
       "      <td>73.85</td>\n",
       "      <td>73.85</td>\n",
       "      <td>73.85</td>\n",
       "      <td>73.85</td>\n",
       "      <td>73.85</td>\n",
       "      <td>73.85</td>\n",
       "      <td>73.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20004811</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20006731</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20008395</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.90</td>\n",
       "      <td>51.90</td>\n",
       "      <td>51.90</td>\n",
       "      <td>51.90</td>\n",
       "      <td>51.90</td>\n",
       "      <td>51.90</td>\n",
       "      <td>51.90</td>\n",
       "      <td>51.90</td>\n",
       "      <td>51.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20010041</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.60</td>\n",
       "      <td>44.60</td>\n",
       "      <td>44.60</td>\n",
       "      <td>44.60</td>\n",
       "      <td>44.60</td>\n",
       "      <td>44.60</td>\n",
       "      <td>44.60</td>\n",
       "      <td>44.60</td>\n",
       "      <td>44.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id  itemid_50801_day_2  itemid_50801_day_6  itemid_50802_day_0  \\\n",
       "0  20004072               164.0               164.0               164.0   \n",
       "1  20004811                67.0                67.0                67.0   \n",
       "2  20006731                75.0                75.0                75.0   \n",
       "3  20008395               135.0               135.0               135.0   \n",
       "4  20010041                12.0                12.0                12.0   \n",
       "\n",
       "   itemid_50802_day_1  itemid_50802_day_2  itemid_50802_day_3  \\\n",
       "0               164.0               164.0               164.0   \n",
       "1                67.0                67.0                67.0   \n",
       "2                75.0                75.0                75.0   \n",
       "3               135.0               135.0               135.0   \n",
       "4                12.0                12.0                12.0   \n",
       "\n",
       "   itemid_50802_day_4  itemid_50802_day_5  itemid_50802_day_6  ...  \\\n",
       "0               164.0               164.0               164.0  ...   \n",
       "1                67.0                67.0                67.0  ...   \n",
       "2                75.0                75.0                75.0  ...   \n",
       "3               135.0               135.0               135.0  ...   \n",
       "4                12.0                12.0                12.0  ...   \n",
       "\n",
       "   itemid_53173_day_4  itemid_53173_day_6  itemid_53174_day_0  \\\n",
       "0               73.85               73.85               73.85   \n",
       "1               87.00               87.00               87.00   \n",
       "2               91.00               91.00               91.00   \n",
       "3               51.90               51.90               51.90   \n",
       "4               44.60               44.60               44.60   \n",
       "\n",
       "   itemid_53174_day_1  itemid_53174_day_2  itemid_53174_day_3  \\\n",
       "0               73.85               73.85               73.85   \n",
       "1               87.00               87.00               87.00   \n",
       "2               91.00               91.00               91.00   \n",
       "3               51.90               51.90               51.90   \n",
       "4               44.60               44.60               44.60   \n",
       "\n",
       "   itemid_53174_day_4  itemid_53174_day_6  itemid_53180_day_1  target  \n",
       "0               73.85               73.85               73.85       1  \n",
       "1               87.00               87.00               87.00       0  \n",
       "2               91.00               91.00               91.00       0  \n",
       "3               51.90               51.90               51.90       0  \n",
       "4               44.60               44.60               44.60       0  \n",
       "\n",
       "[5 rows x 2199 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0fe38a",
   "metadata": {},
   "source": [
    "# Training a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36d128b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac0b51e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
