{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a064a422",
   "metadata": {},
   "source": [
    "## Show the tables in schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2ec9e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 18:57:21,045 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-06-21 18:57:21,046 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-06-21 18:57:21,047 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-06-21 18:57:21,047 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-06-21 18:57:21,048 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-06-21 18:57:21,048 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "Schema: mimiciv_icu\n",
      "2025-06-21 18:57:21,050 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-21 18:57:21,050 INFO sqlalchemy.engine.Engine SELECT table_name FROM information_schema.tables WHERE table_schema = %(schema)s\n",
      "2025-06-21 18:57:21,050 INFO sqlalchemy.engine.Engine [generated in 0.00076s] {'schema': 'mimiciv_icu'}\n",
      "['caregiver', 'chartevents', 'datetimeevents', 'd_items', 'icustays', 'ingredientevents', 'inputevents', 'outputevents', 'procedureevents']\n",
      "Schema: mimiciv_hosp\n",
      "2025-06-21 18:57:21,063 INFO sqlalchemy.engine.Engine SELECT table_name FROM information_schema.tables WHERE table_schema = %(schema)s\n",
      "2025-06-21 18:57:21,064 INFO sqlalchemy.engine.Engine [cached since 0.01414s ago] {'schema': 'mimiciv_hosp'}\n",
      "['admissions', 'd_hcpcs', 'diagnoses_icd', 'd_icd_diagnoses', 'd_icd_procedures', 'd_labitems', 'drgcodes', 'emar_detail', 'emar', 'hcpcsevents', 'labevents', 'microbiologyevents', 'omr', 'patients', 'pharmacy', 'poe_detail', 'poe', 'prescriptions', 'procedures_icd', 'provider', 'services', 'transfers']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))  # adding the parent directory of 'notebooks' to sys.path\n",
    "from db_utils.db_setup import Database\n",
    "from sqlalchemy import text\n",
    "engine = Database()\n",
    "schema_list = [\"mimiciv_icu\", \"mimiciv_hosp\"]\n",
    "for schema in schema_list:\n",
    "    print(f\"Schema: {schema}\")\n",
    "    tables = Database.show_tables_in_schema(engine, schema)\n",
    "    print(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526cc2c0",
   "metadata": {},
   "source": [
    "# Getting all `labevents` data and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb8590",
   "metadata": {},
   "source": [
    "##### Fetching `demographic` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76c84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "url = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(url)\n",
    "conn = engine.connect()\n",
    "cursor = conn.connection.cursor()\n",
    "\n",
    "# Creating a TEMPORARY table\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TEMP TABLE temp_cohort (\n",
    "        subject_id INT,\n",
    "        hadm_id INT,\n",
    "        admittime TIMESTAMP,\n",
    "        dischtime TIMESTAMP,\n",
    "        target  INT\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Loading the CSV and insert into temp_cohort\n",
    "cohort_df = pd.read_csv('../assets/cohort1_target.csv')\n",
    "cohort_df['admittime'] = pd.to_datetime(cohort_df['admittime'], errors='coerce')\n",
    "cohort_df['dischtime'] = pd.to_datetime(cohort_df['dischtime'], errors='coerce')\n",
    "\n",
    "values = list(cohort_df.itertuples(index=False, name=None))\n",
    "execute_values(cursor,\n",
    "    \"INSERT INTO temp_cohort (subject_id, hadm_id, admittime, dischtime, target) VALUES %s\",\n",
    "    values\n",
    ")\n",
    "\n",
    "# Fetching demographic data from admissions table\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        c.subject_id,\n",
    "        c.hadm_id,\n",
    "        c.admittime,\n",
    "        c.dischtime,\n",
    "        c.target,\n",
    "        p.gender,\n",
    "        p.anchor_age,\n",
    "        a.race\n",
    "    FROM temp_cohort c\n",
    "    JOIN mimiciv_hosp.admissions a ON c.hadm_id = a.hadm_id\n",
    "    JOIN mimiciv_hosp.patients p ON a.subject_id = p.subject_id\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Finally creating DataFrame \n",
    "columns = ['subject_id', 'hadm_id', 'admittime', 'dischtime', 'target', 'gender', 'anchor_age', 'race']\n",
    "final_df = pd.DataFrame(rows, columns=columns)\n",
    "# Save the final DataFrame to a Parquet file\n",
    "final_df['admittime'] = pd.to_datetime(final_df['admittime'], errors='coerce')\n",
    "final_df['dischtime'] = pd.to_datetime(final_df['dischtime'], errors='coerce')\n",
    "final_df['anchor_age'] = pd.to_numeric(final_df['anchor_age'], errors='coerce')\n",
    "final_df['target'] = pd.to_numeric(final_df['target'], errors='coerce')\n",
    "final_df.to_parquet(\"../dataset/raw/cohort_with_demographic_data.parquet\", index=False)\n",
    "\n",
    "# Finalize\n",
    "conn.connection.commit()\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59836616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>lab_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [subject_id, hadm_id, lab_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_ids = [\n",
    "    (14634633, 28387252),\n",
    "    (17957482, 20759114),\n",
    "    (12956096, 27116694),\n",
    "    (11101913, 27589462),\n",
    "    (12593003, 25929337),\n",
    "    (13474206, 21575924),\n",
    "    (12956096, 21897330),\n",
    "    (11338207, 23582798),\n",
    "    (13474206, 24246939),\n",
    "    (18215560, 22709370)\n",
    "]\n",
    "\n",
    "\n",
    "engine = create_engine(url)\n",
    "conn = engine.connect()\n",
    "cursor = conn.connection.cursor()\n",
    "# Build a SQL-friendly string\n",
    "id_tuple_str = \",\".join(f\"({sid},{hid})\" for sid, hid in missing_ids)\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT le.subject_id, le.hadm_id, COUNT(*) as lab_count\n",
    "    FROM mimiciv_hosp.labevents le\n",
    "    WHERE (le.subject_id, le.hadm_id) IN ({id_tuple_str})\n",
    "    GROUP BY le.subject_id, le.hadm_id\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query)\n",
    "data = cursor.fetchall()\n",
    "df = pd.DataFrame(data, columns=['subject_id', 'hadm_id', 'lab_count'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d69176a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total missing (subject_id, hadm_id) pairs: 372\n",
      "First 10 missing:\n",
      "(10275673, 20335833)\n",
      "(10470555, 23490435)\n",
      "(10472840, 22711151)\n",
      "(10540938, 22151813)\n",
      "(10540938, 23239998)\n",
      "(10540938, 24081400)\n",
      "(10540938, 26471128)\n",
      "(10540938, 26728577)\n",
      "(10540938, 28150003)\n",
      "(10540938, 28412117)\n"
     ]
    }
   ],
   "source": [
    "# Load files\n",
    "demog_df = pd.read_parquet(\"../dataset/raw/lab_event_data_with_demographics.parquet\")\n",
    "cohort_df = pd.read_csv('../assets/extracted.csv')\n",
    "\n",
    "# Ensure consistent dtypes\n",
    "cohort_df['subject_id'] = cohort_df['subject_id'].astype(int)\n",
    "cohort_df['admid'] = cohort_df['admid'].astype(int)\n",
    "demog_df['subject_id'] = demog_df['subject_id'].astype(int)\n",
    "demog_df['hadm_id'] = demog_df['hadm_id'].astype(int)\n",
    "\n",
    "# Create sets of (subject_id, hadm_id) pairs\n",
    "cohort_pairs = set(zip(cohort_df['subject_id'], cohort_df['admid']))\n",
    "demog_pairs = set(zip(demog_df['subject_id'], demog_df['hadm_id']))\n",
    "\n",
    "# Identify missing pairs\n",
    "missing_pairs = sorted(cohort_pairs - demog_pairs)\n",
    "\n",
    "print(f\"✅ Total missing (subject_id, hadm_id) pairs: {len(missing_pairs)}\")\n",
    "print(\"First 10 missing:\")\n",
    "for pair in missing_pairs[:10]:\n",
    "    print(pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205da09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>label</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>charttime</th>\n",
       "      <th>admid</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>minute</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50861</td>\n",
       "      <td>AlanineAminotransferase(ALT)</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2117-12-18 10:12:00</td>\n",
       "      <td>21586397</td>\n",
       "      <td>10010231</td>\n",
       "      <td>2481</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50862</td>\n",
       "      <td>Albumin</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2117-12-18 10:12:00</td>\n",
       "      <td>21586397</td>\n",
       "      <td>10010231</td>\n",
       "      <td>2481</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50863</td>\n",
       "      <td>AlkalinePhosphatase</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2117-12-18 10:12:00</td>\n",
       "      <td>21586397</td>\n",
       "      <td>10010231</td>\n",
       "      <td>2481</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50868</td>\n",
       "      <td>AnionGap</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2117-12-18 10:12:00</td>\n",
       "      <td>21586397</td>\n",
       "      <td>10010231</td>\n",
       "      <td>2481</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50878</td>\n",
       "      <td>AsparateAminotransferase(AST)</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2117-12-18 10:12:00</td>\n",
       "      <td>21586397</td>\n",
       "      <td>10010231</td>\n",
       "      <td>2481</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemid                          label  valuenum            charttime  \\\n",
       "0   50861   AlanineAminotransferase(ALT)      22.0  2117-12-18 10:12:00   \n",
       "1   50862                        Albumin       3.9  2117-12-18 10:12:00   \n",
       "2   50863            AlkalinePhosphatase      68.0  2117-12-18 10:12:00   \n",
       "3   50868                       AnionGap      15.0  2117-12-18 10:12:00   \n",
       "4   50878  AsparateAminotransferase(AST)      18.0  2117-12-18 10:12:00   \n",
       "\n",
       "      admid  subject_id  minute  hour  day  \n",
       "0  21586397    10010231    2481    41    1  \n",
       "1  21586397    10010231    2481    41    1  \n",
       "2  21586397    10010231    2481    41    1  \n",
       "3  21586397    10010231    2481    41    1  \n",
       "4  21586397    10010231    2481    41    1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8960f785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking missing patients:  31%|███       | 114/372 [2:04:02<4:46:45, 66.69s/it]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Replace with your actual DB connection URL\n",
    "url = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(url)\n",
    "cohort_df = pd.read_csv('../assets/cohort1_target.csv')\n",
    "\n",
    "cohort_df = cohort_df.rename(columns={'admid': 'hadm_id'})\n",
    "\n",
    "dischtime_lookup = {\n",
    "    (int(row.subject_id), int(row.hadm_id)): pd.to_datetime(row.dischtime)\n",
    "    for row in cohort_df.itertuples(index=False)\n",
    "}\n",
    "\n",
    "no_lab = []\n",
    "lab_but_not_in_window = []\n",
    "lab_in_window = []\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    for sid, hid in tqdm(missing_pairs, desc=\"Checking missing patients\"):\n",
    "        # 1. Check if any lab events exist at all\n",
    "        query = text(\"\"\"\n",
    "            SELECT charttime FROM mimiciv_hosp.labevents \n",
    "            WHERE subject_id = :sid AND hadm_id = :hid\n",
    "        \"\"\")\n",
    "        result = conn.execute(query, {\"sid\": sid, \"hid\": hid}).fetchall()\n",
    "\n",
    "        if not result:\n",
    "            no_lab.append((sid, hid))\n",
    "            continue\n",
    "\n",
    "        # 2. Check if any lab event is within 7 days before discharge\n",
    "        if (sid, hid) not in dischtime_lookup:\n",
    "            print(f\"⚠️ Missing dischtime for {sid}, {hid}\")\n",
    "            continue\n",
    "\n",
    "        disch_time = dischtime_lookup[(sid, hid)]\n",
    "        in_window = any(\n",
    "            disch_time - pd.Timedelta(days=7) <= pd.to_datetime(r[0]) <= disch_time\n",
    "            for r in result\n",
    "        )\n",
    "\n",
    "        if in_window:\n",
    "            lab_in_window.append((sid, hid))\n",
    "        else:\n",
    "            lab_but_not_in_window.append((sid, hid))\n",
    "\n",
    "# Summary\n",
    "print(\"\\n✅ Summary of Missing Patients Classification:\")\n",
    "print(f\"Total missing patients checked: {len(missing_pairs)}\")\n",
    "print(f\"➤ No lab events at all: {len(no_lab)}\")\n",
    "print(f\"➤ Lab events, but none within 7-day window: {len(lab_but_not_in_window)}\")\n",
    "print(f\"➤ Lab events in window (unexpectedly excluded): {len(lab_in_window)}\")\n",
    "\n",
    "# Optional: Save for inspection\n",
    "pd.DataFrame(no_lab, columns=[\"subject_id\", \"hadm_id\"]).to_csv(\"no_lab_events.csv\", index=False)\n",
    "pd.DataFrame(lab_but_not_in_window, columns=[\"subject_id\", \"hadm_id\"]).to_csv(\"lab_outside_window.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def map_race(race):\n",
    "    if pd.isna(race):\n",
    "        return 'Unknown or Not Reported'\n",
    "    \n",
    "    race = race.upper()\n",
    "    \n",
    "    if 'HISPANIC' in race or 'LATINO' in race or 'SOUTH AMERICAN' in race:\n",
    "        return 'Hispanic or Latino'\n",
    "    elif 'WHITE' in race:\n",
    "        return 'White'\n",
    "    elif 'BLACK' in race or 'AFRICAN' in race:\n",
    "        return 'Black or African American'\n",
    "    elif 'ASIAN' in race:\n",
    "        return 'Asian'\n",
    "    elif 'PACIFIC ISLANDER' in race or 'NATIVE HAWAIIAN' in race:\n",
    "        return 'Native Hawaiian or Other Pacific Islander'\n",
    "    elif 'AMERICAN INDIAN' in race or 'ALASKA NATIVE' in race:\n",
    "        return 'American Indian or Alaska Native'\n",
    "    elif 'DECLINED' in race or 'UNABLE' in race or 'UNKNOWN' in race:\n",
    "        return 'Unknown or Not Reported'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "le = LabelEncoder()\n",
    "demog_df['race_grouped'] = demog_df['race'].apply(map_race)  # apply your earlier grouping\n",
    "demog_df['race_target'] = le.fit_transform(demog_df['race_grouped'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22363332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique ages and races\n",
    "print(\"Unique ages:\", final_df['anchor_age'].unique())\n",
    "print(\"Unique races:\", final_df['race'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2b4217",
   "metadata": {},
   "source": [
    "##### Fetching labevents data prior `7` or `14` days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dcebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "import pandas as pd\n",
    "\n",
    "logger.info(\"Starting lab data extraction process.\")\n",
    "\n",
    "# First get all unique patient IDs\n",
    "patient_ids = pd.read_sql(\"SELECT DISTINCT subject_id FROM public.temp_cohort ORDER BY subject_id\", engine)\n",
    "logger.info(f\"Fetched {len(patient_ids)} unique patient IDs from temp_cohort.\")\n",
    "\n",
    "lab_df = pd.DataFrame()\n",
    "\n",
    "batch_size = 100\n",
    "total_batches = (len(patient_ids) + batch_size - 1) // batch_size\n",
    "logger.info(f\"Processing patient data in batches of {batch_size}, total batches: {total_batches}\")\n",
    "\n",
    "for i in range(0, len(patient_ids), batch_size):\n",
    "    batch_num = i // batch_size + 1\n",
    "    batch = patient_ids.iloc[i:i+batch_size]\n",
    "    batch_list = tuple(batch['subject_id'])\n",
    "    \n",
    "    logger.info(f\"Processing batch {batch_num}/{total_batches} with {len(batch)} patient IDs.\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            le.subject_id, \n",
    "            le.hadm_id, \n",
    "            le.itemid, \n",
    "            le.charttime, \n",
    "            le.valuenum,\n",
    "            tc.dischtime,\n",
    "            tc.target\n",
    "        FROM mimiciv_hosp.labevents le\n",
    "        JOIN public.temp_cohort tc\n",
    "          ON le.subject_id = tc.subject_id\n",
    "         AND le.hadm_id = tc.hadm_id\n",
    "        WHERE le.charttime BETWEEN (tc.dischtime - INTERVAL '7 days') AND tc.dischtime\n",
    "        AND le.subject_id IN {batch_list}\n",
    "    \"\"\"\n",
    "    \n",
    "    chunk = pd.read_sql(query, engine)\n",
    "    logger.info(f\"Batch {batch_num} fetched {len(chunk)} lab event records.\")\n",
    "    \n",
    "    lab_df = pd.concat([lab_df, chunk], ignore_index=True)\n",
    "\n",
    "lab_df.reset_index(drop=True, inplace=True)\n",
    "logger.info(f\"Lab data extraction complete. Total records collected: {len(lab_df)}\")\n",
    "logger.info(\"Saving lab data to Parquet file.\")\n",
    "lab_df.to_parquet(\"../dataset/raw/lab_event_data_with_demographics.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5118bd",
   "metadata": {},
   "source": [
    "# Pre-processing for tabular data\n",
    "\n",
    "### Aggregating on an `hourly` basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ac671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "patient_data_df = pd.read_parquet(\"../dataset/raw/lab_event_data_with_demographics.parquet\")\n",
    "sup_df = pd.read_csv(\"../assets/ts.csv\")  \n",
    "sup_extracted_df = pd.read_csv(\"../assets/extracted.csv\")\n",
    "cohort_df = pd.read_csv(\"../assets/cohort1_target.csv\")\n",
    "# len(patient_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cb2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4908, 239990, 1092498, 5308)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patient_data_df['hadm_id'].unique()), len(sup_df), len(sup_extracted_df), len(cohort_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37be63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>itemid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>target</th>\n",
       "      <th>gender</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10014354</td>\n",
       "      <td>26486158</td>\n",
       "      <td>50822</td>\n",
       "      <td>2148-09-01 18:47:00</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2148-09-08 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "      <td>WHITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10014354</td>\n",
       "      <td>26486158</td>\n",
       "      <td>50861</td>\n",
       "      <td>2148-09-01 14:05:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2148-09-08 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "      <td>WHITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10014354</td>\n",
       "      <td>26486158</td>\n",
       "      <td>50861</td>\n",
       "      <td>2148-09-02 00:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2148-09-08 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "      <td>WHITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10014354</td>\n",
       "      <td>26486158</td>\n",
       "      <td>50861</td>\n",
       "      <td>2148-09-02 04:29:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2148-09-08 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "      <td>WHITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10014354</td>\n",
       "      <td>26486158</td>\n",
       "      <td>50861</td>\n",
       "      <td>2148-09-02 07:37:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2148-09-08 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "      <td>WHITE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  itemid           charttime  valuenum  \\\n",
       "0    10014354  26486158   50822 2148-09-01 18:47:00       3.8   \n",
       "1    10014354  26486158   50861 2148-09-01 14:05:00       7.0   \n",
       "2    10014354  26486158   50861 2148-09-02 00:00:00       8.0   \n",
       "3    10014354  26486158   50861 2148-09-02 04:29:00       7.0   \n",
       "4    10014354  26486158   50861 2148-09-02 07:37:00       7.0   \n",
       "\n",
       "            dischtime  target gender  anchor_age   race  \n",
       "0 2148-09-08 12:00:00       0      M          60  WHITE  \n",
       "1 2148-09-08 12:00:00       0      M          60  WHITE  \n",
       "2 2148-09-08 12:00:00       0      M          60  WHITE  \n",
       "3 2148-09-08 12:00:00       0      M          60  WHITE  \n",
       "4 2148-09-08 12:00:00       0      M          60  WHITE  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a6811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ts.csv (daily binned data per (admid, itemid))\n",
    "ts_df = sup_df.copy()\n",
    "\n",
    "# Set MultiIndex\n",
    "ts_df.set_index([\"admid\", \"itemid\"], inplace=True)\n",
    "\n",
    "# Unstack to reshape so each row = 1 admission\n",
    "reshaped = ts_df.unstack(level=1)\n",
    "\n",
    "# Flatten MultiIndex columns: (day, itemid) → itemid_day\n",
    "reshaped.columns = [f\"itemid_{item}_{day}d\" for day, item in reshaped.columns]\n",
    "\n",
    "# Reset index to make admid a column\n",
    "reshaped = reshaped.reset_index()\n",
    "\n",
    "# Impute missing values (example: fillna with 0 or use KNNImputer)\n",
    "# Option 1: Fill NaNs with 0\n",
    "imputed = reshaped.fillna(0)\n",
    "\n",
    "# Option 2: KNN Imputer\n",
    "# from sklearn.impute import KNNImputer\n",
    "# imputer = KNNImputer(n_neighbors=5)\n",
    "# imputed = pd.DataFrame(imputer.fit_transform(reshaped.iloc[:, 1:]), columns=reshaped.columns[1:])\n",
    "# imputed.insert(0, 'admid', reshaped['admid'].values)\n",
    "\n",
    "# imputed is now ready for model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597aa4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patient_data_df['hadm_id'].unique()) == len(sup_extracted_df['admid'].unique())  # Number of unique patients in the patient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a516fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_df['hadm_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188233bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only in patient_data_df: set()\n",
      "Only in sup_df: {np.int64(28049409), np.int64(24512520), np.int64(29966344), np.int64(23732248), np.int64(26859546), np.int64(24348699), np.int64(25581599), np.int64(29601847), np.int64(23566395), np.int64(28069955), np.int64(24105031), np.int64(23582798), np.int64(23343183), np.int64(27936855), np.int64(27109464), np.int64(21479513), np.int64(24238176), np.int64(28002410), np.int64(29954155), np.int64(29978734), np.int64(21897330), np.int64(22063223), np.int64(27164792), np.int64(27801728), np.int64(26728577), np.int64(29429890), np.int64(28745870), np.int64(27752592), np.int64(26646673), np.int64(27390097), np.int64(24320151), np.int64(21457047), np.int64(29726889), np.int64(28928169), np.int64(21547199), np.int64(21080270), np.int64(28412117), np.int64(29712617), np.int64(28150003), np.int64(21575924), np.int64(27189494), np.int64(29303040), np.int64(28754176), np.int64(28461313), np.int64(27646210), np.int64(25872649), np.int64(20220172), np.int64(24942865), np.int64(23851288), np.int64(20361497), np.int64(28563737), np.int64(28721439), np.int64(25407777), np.int64(28447011), np.int64(27779379), np.int64(28459319), np.int64(28680506), np.int64(28182845), np.int64(27081024), np.int64(24762693), np.int64(27042123), np.int64(26005838), np.int64(24605015), np.int64(20603231), np.int64(29843807), np.int64(25897317), np.int64(28864876), np.int64(25817452), np.int64(27400562), np.int64(23869822), np.int64(21053823), np.int64(28342657), np.int64(29778307), np.int64(26896778), np.int64(26141067), np.int64(29604237), np.int64(22083984), np.int64(20666774), np.int64(23454105), np.int64(23898523), np.int64(23325087), np.int64(24222129), np.int64(29710770), np.int64(28424631), np.int64(27605433), np.int64(23159227), np.int64(28668365), np.int64(27627983), np.int64(20808151), np.int64(26943963), np.int64(21338592), np.int64(21029345), np.int64(25569770), np.int64(21031406), np.int64(21047792), np.int64(28674549), np.int64(20167161), np.int64(25504258), np.int64(27630083), np.int64(23613954), np.int64(27503115), np.int64(26956301), np.int64(20425230), np.int64(24621582), np.int64(26661390), np.int64(21389849), np.int64(24920609), np.int64(22872612), np.int64(26067495), np.int64(20269608), np.int64(28523054), np.int64(28258863), np.int64(24111664), np.int64(25209395), np.int64(23726646), np.int64(22854199), np.int64(22600251), np.int64(27243073), np.int64(25997891), np.int64(23288387), np.int64(25334344), np.int64(20759114), np.int64(24676946), np.int64(20376148), np.int64(28942934), np.int64(23722583), np.int64(26946137), np.int64(25420378), np.int64(24562276), np.int64(24586857), np.int64(25573997), np.int64(21377647), np.int64(21928562), np.int64(22774391), np.int64(25172601), np.int64(23982719), np.int64(28506755), np.int64(25567876), np.int64(22151813), np.int64(28086921), np.int64(22084239), np.int64(21072538), np.int64(24246939), np.int64(29115036), np.int64(23554725), np.int64(26604202), np.int64(26522285), np.int64(27601583), np.int64(29311688), np.int64(20193995), np.int64(26655440), np.int64(20503254), np.int64(21514968), np.int64(26471128), np.int64(22766313), np.int64(22391538), np.int64(25649906), np.int64(27781912), np.int64(22330143), np.int64(21631780), np.int64(29279021), np.int64(24838960), np.int64(23421751), np.int64(24544065), np.int64(22676292), np.int64(27851589), np.int64(20882252), np.int64(25332558), np.int64(24394576), np.int64(23071569), np.int64(25150291), np.int64(23077718), np.int64(27589462), np.int64(28824409), np.int64(24146779), np.int64(22711151), np.int64(20611963), np.int64(24773507), np.int64(22733701), np.int64(20808583), np.int64(21117842), np.int64(21726099), np.int64(29086624), np.int64(28933031), np.int64(23186344), np.int64(20466602), np.int64(26725296), np.int64(26254265), np.int64(20419517), np.int64(24660937), np.int64(27716559), np.int64(29209569), np.int64(28271589), np.int64(29223913), np.int64(23127032), np.int64(24081400), np.int64(27843582), np.int64(20028418), np.int64(23112723), np.int64(27532309), np.int64(24615965), np.int64(25650205), np.int64(24087591), np.int64(29166656), np.int64(27202630), np.int64(27358280), np.int64(22377547), np.int64(24355924), np.int64(27870301), np.int64(25406564), np.int64(26727534), np.int64(22709370), np.int64(26555536), np.int64(28914835), np.int64(24102036), np.int64(26633363), np.int64(27116694), np.int64(24290464), np.int64(20890789), np.int64(25339051), np.int64(21812395), np.int64(25394352), np.int64(28126401), np.int64(26864837), np.int64(21671112), np.int64(20419785), np.int64(20427978), np.int64(21054670), np.int64(25021651), np.int64(25330905), np.int64(28447961), np.int64(20335833), np.int64(20565210), np.int64(28478686), np.int64(27161835), np.int64(27518190), np.int64(22734073), np.int64(22250749), np.int64(22611203), np.int64(26930440), np.int64(21359881), np.int64(27526412), np.int64(28574991), np.int64(25935128), np.int64(25474330), np.int64(25789726), np.int64(29766942), np.int64(25806110), np.int64(20737318), np.int64(26606899), np.int64(20550974), np.int64(23239998), np.int64(20358467), np.int64(29676873), np.int64(29613386), np.int64(24968523), np.int64(22396237), np.int64(24372557), np.int64(20358484), np.int64(28661085), np.int64(24913257), np.int64(28382570), np.int64(28562795), np.int64(22113641), np.int64(23117168), np.int64(28106102), np.int64(27334012), np.int64(24673662), np.int64(21034374), np.int64(26238351), np.int64(29631891), np.int64(24503706), np.int64(23483803), np.int64(27782557), np.int64(28560806), np.int64(27860391), np.int64(23596478), np.int64(21126616), np.int64(28335586), np.int64(22554088), np.int64(27915772), np.int64(26390021), np.int64(28014087), np.int64(29588999), np.int64(26359305), np.int64(22533650), np.int64(28153372), np.int64(28104221), np.int64(27192871), np.int64(20102696), np.int64(21481002), np.int64(27700779), np.int64(23019051), np.int64(22472239), np.int64(22451763), np.int64(28843588), np.int64(21388885), np.int64(24600150), np.int64(27373146), np.int64(25136739), np.int64(29628009), np.int64(24766068), np.int64(25929337), np.int64(24485498), np.int64(21282425), np.int64(26199673), np.int64(25646714), np.int64(28436101), np.int64(28630663), np.int64(24661657), np.int64(24219291), np.int64(25153183), np.int64(21489315), np.int64(23488168), np.int64(20954796), np.int64(22970043), np.int64(23762628), np.int64(22408902), np.int64(28935879), np.int64(24315600), np.int64(23971536), np.int64(23279314), np.int64(20293332), np.int64(29175522), np.int64(21763811), np.int64(24942308), np.int64(22206182), np.int64(23385835), np.int64(28782322), np.int64(20244210), np.int64(29275897), np.int64(24221435), np.int64(21470976), np.int64(22546178), np.int64(25554695), np.int64(21532427), np.int64(27330324), np.int64(28948249), np.int64(22269729), np.int64(25216834), np.int64(20000588), np.int64(21436241), np.int64(25784169), np.int64(28651373), np.int64(20361070), np.int64(22310780), np.int64(22806397), np.int64(23095168), np.int64(23230337), np.int64(23490435), np.int64(29878152), np.int64(24289165), np.int64(25976717), np.int64(20133786), np.int64(23543711), np.int64(26556320), np.int64(26912673), np.int64(21329836), np.int64(23257006), np.int64(28889010), np.int64(28387252), np.int64(24645569), np.int64(26716104), np.int64(25915339), np.int64(25536460), np.int64(24782805), np.int64(25204696), np.int64(29482984), np.int64(21108715), np.int64(29323249), np.int64(24029172), np.int64(26859516)}\n"
     ]
    }
   ],
   "source": [
    "# patient_data_df.drop_duplicates(subset=['hadm_id', 'subject_id', 'itemid'], inplace=True)\n",
    "hadm_ids = set(patient_data_df['hadm_id'].unique())\n",
    "admid_ids = set(sup_extracted_df['admid'].unique())\n",
    "\n",
    "print(\"Only in patient_data_df:\", hadm_ids - admid_ids)\n",
    "print(\"Only in sup_df:\", admid_ids - hadm_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a492c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4908"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patient_data_df['hadm_id'].unique())  # Number of unique admissions in the patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b515bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "# Create a copy and convert timestamps\n",
    "new_df = patient_data_df.copy()\n",
    "new_df[\"charttime\"] = pd.to_datetime(new_df[\"charttime\"])\n",
    "new_df[\"dischtime\"] = pd.to_datetime(new_df[\"dischtime\"])\n",
    "\n",
    "# Calculate hours before discharge\n",
    "new_df[\"hours_before_discharge\"] = (new_df[\"dischtime\"] - new_df[\"charttime\"]).dt.total_seconds() / 3600\n",
    "\n",
    "# Filter to 12-hour window (0 to 12 hours inclusive)\n",
    "new_df_filtered = new_df[\n",
    "    (new_df[\"hours_before_discharge\"] >= 0) & (new_df[\"hours_before_discharge\"] <= 168)\n",
    "].copy()    \n",
    "\n",
    "print(f\"Processing {len(new_df_filtered)} records within 12-hour window...\")\n",
    "\n",
    "# creating 7 day bins\n",
    "new_df_filtered[\"hour_bin\"] = (np.floor(new_df_filtered[\"hours_before_discharge\"]/6) + 1).astype(int)\n",
    "new_df_filtered[\"hour_bin\"] = new_df_filtered[\"hour_bin\"].clip(upper=27)  # Cap at 7\n",
    "\n",
    "# Create feature_id with hour bin\n",
    "new_df_filtered[\"feature_id\"] = (\n",
    "    \"itemid_\" + \n",
    "    new_df_filtered[\"itemid\"].astype(str) + \n",
    "    \"_last_\" + \n",
    "    new_df_filtered[\"hour_bin\"].astype(str) + \n",
    "    \"h\"\n",
    ")\n",
    "\n",
    "# Pivot numeric features (mean aggregation)\n",
    "numeric_pivot = new_df_filtered.pivot_table(\n",
    "    index=\"hadm_id\",\n",
    "    columns=\"feature_id\",\n",
    "    values=\"valuenum\",\n",
    "    aggfunc=\"mean\",\n",
    "    # fill_value=np.nan,\n",
    ")\n",
    "# Pivot binary features (existence indicator)\n",
    "new_df_filtered[\"has_measurement\"] = 1\n",
    "binary_pivot = new_df_filtered.pivot_table(\n",
    "    index=\"hadm_id\",\n",
    "    columns=\"feature_id\",\n",
    "    values=\"has_measurement\",\n",
    "    aggfunc=\"max\",  # 1 if any measurement exists\n",
    "    fill_value=0,\n",
    ")\n",
    "binary_pivot.columns = [col + \"_measured\" for col in binary_pivot.columns]\n",
    "\n",
    "# Step 3: Impute missing values using KNN\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "ts_user_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(numeric_pivot),\n",
    "    columns=numeric_pivot.columns,\n",
    "    index=numeric_pivot.index\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "# Get targets\n",
    "targets = new_df_filtered[[\"hadm_id\", \"target\"]].drop_duplicates().set_index(\"hadm_id\")\n",
    "\n",
    "# Combine features with targets (NO forward/backward fill)\n",
    "numeric_features = numeric_pivot.join(targets).reset_index()\n",
    "binary_features = binary_pivot.join(targets).reset_index()\n",
    "\n",
    "print(f\"Created numeric features: {numeric_features.shape}\")\n",
    "print(f\"Created binary features: {binary_features.shape}\")\n",
    "print(f\"Filtered down to {len(new_df_filtered)} rows from {len(new_df)}\")\n",
    "print(f\"Number of unique hadm_ids: {new_df_filtered['hadm_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94aee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "28 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1952df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Supervisor shape:\", ts_supervisor_final.shape)\n",
    "print(\"User shape:\", binary_features.shape)\n",
    "\n",
    "# Optional: inspect overlapping features\n",
    "common_columns = set(ts_supervisor_final.columns) & set(binary_features.columns)\n",
    "print(\"Common features:\", len(common_columns))\n",
    "\n",
    "# Check hadm_id consistency\n",
    "print(\"Same hadm_ids:\", set(ts_supervisor_final['admid']) == set(binary_features['hadm_id']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0fe38a",
   "metadata": {},
   "source": [
    "# Preprocessing for Temporal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d128b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1170853"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "patient_data_df = pd.read_parquet(\"../dataset/raw/lab_event_data_with_demographics.parquet\")\n",
    "len(patient_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fea5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = patient_data_df.copy()\n",
    "\n",
    "# Drop unnecessary columns [\"race\", \"gender\", \"anchor_age\", \"target\"]\n",
    "temp_df = temp_df.drop(columns=[\"race\", \"gender\", \"anchor_age\", \"target\"])\n",
    "\n",
    "# Then drop duplicates based on [\"subject_id\", \"hadm_id\", \"itemid\", \"charttime\"]\n",
    "temp_df = temp_df.drop_duplicates(subset=[\"subject_id\", \"hadm_id\", \"itemid\", \"charttime\"])\n",
    "\n",
    "temp_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f43389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def assign_time_bin(hours_before_discharge, window_hours=6):\n",
    "    \"\"\"Assign records to fixed time bins (e.g., 0-6h, 6-12h).\n",
    "    Example: For a 6-hour window:\n",
    "        0.5h → bin 0, 6.1h → bin 6, 23h → bin 18\n",
    "    \"\"\"\n",
    "    return (np.floor(hours_before_discharge / window_hours) * window_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427e244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = temp_df.copy()\n",
    "max_window_days = 7\n",
    "time_bin_hours = 12\n",
    "\n",
    "# Convert charttime and dischtime to datetime\n",
    "unique_items = df[\"itemid\"].unique()\n",
    "# creating a dictionary to map itemid to index \n",
    "# because the itemid can be large and sparse\n",
    "inputdict = {item: idx for idx, item in enumerate(unique_items)}\n",
    "n_features = len(inputdict)\n",
    "\n",
    "# calculating hours before discharge and filter window\n",
    "df[\"hours_before_discharge\"] = (df[\"dischtime\"] - df[\"charttime\"]).dt.total_seconds() / 3600\n",
    "df = df[(df[\"hours_before_discharge\"] >= 0) & \n",
    "        (df[\"hours_before_discharge\"] <= max_window_days * 24)]\n",
    "\n",
    "# 3. Assign time bins (aligned to discharge)\n",
    "df['time_bin'] = (np.floor(df['hours_before_discharge'] / time_bin_hours) \n",
    "                    * time_bin_hours)\n",
    "\n",
    "# Grouping by patient and time bin\n",
    "grouped = df.sort_values([\"subject_id\", \"hadm_id\", \"time_bin\"])\\\n",
    "            .groupby([\"subject_id\", \"hadm_id\", \"time_bin\"])\n",
    "\n",
    "# Initializing arrays to hold features, masking, timestamps, and patient IDs\n",
    "n_timesteps = len(grouped)\n",
    "x = np.zeros((n_features, n_timesteps))\n",
    "masking = np.zeros_like(x)\n",
    "timestamps = np.zeros(n_timesteps)\n",
    "patient_ids = []\n",
    "\n",
    "# Populating arrays to  hold features, masking, timestamps, and patient IDs\n",
    "for i, ((subj_id, adm_id, time_bin), group) in enumerate(grouped):\n",
    "    # get the time bin as a timestamp\n",
    "    timestamps[i] = time_bin\n",
    "    patient_ids.append(f\"{subj_id}_{adm_id}\")\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        # get the feature index from the inputdict\n",
    "        feat_idx = inputdict[row[\"itemid\"]]\n",
    "        # Fill the feature value and masking\n",
    "        x[feat_idx, i] = row[\"valuenum\"]\n",
    "        # Set masking to 1 if the feature is present\n",
    "        masking[feat_idx, i] = 1\n",
    "\n",
    "# Calculating delta (time since last observation)\n",
    "delta = np.zeros_like(x)\n",
    "for i in range(1, n_timesteps):\n",
    "    # calculate the time gap between the current and previous time bin\n",
    "    time_gap = timestamps[i-1] - timestamps[i]  # Note: reversed for \"before discharge\"\n",
    "    # if the previous time bin was missing, accumulate the time gap\n",
    "    # else use the actual time gap\n",
    "    delta[:, i] = np.where(\n",
    "        masking[:, i-1] == 0,\n",
    "        time_gap + delta[:, i-1],  # Accumulate if missing\n",
    "        time_gap                   # Else use actual gap\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb30703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta[0, 0:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb5f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "masking[0, 0:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799fd2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[3, 0:30] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e88282",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, masking.shape, delta.shape, timestamps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39305a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def df_to_x_m_d(df, max_window_days=7):\n",
    "    \"\"\"\n",
    "    Convert DataFrame to GRU-D inputs (x, masking, delta), using raw `itemid` as indices.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns ['subject_id', 'hadm_id', 'itemid', 'charttime', 'valuenum', 'dischtime'].\n",
    "        max_window_days: Maximum days before discharge to include.\n",
    "    \n",
    "    Returns:\n",
    "        x: Feature matrix of shape (n_features, n_timesteps).\n",
    "        masking: Binary mask of observed values (same shape as x).\n",
    "        delta: Time gaps since last observation (same shape as x).\n",
    "        timestamps: Hours since discharge for each timestep.\n",
    "        ids: DataFrame with ['subject_id', 'hadm_id'] for each timestep.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1. Preprocess Timestamps ---\n",
    "    df[\"hours_since_discharge\"] = (df[\"dischtime\"] - df[\"charttime\"]).dt.total_seconds() / 3600\n",
    "\n",
    "    # Filter to keep only within the max window\n",
    "    df = df[(df[\"hours_since_discharge\"] >= 0) & (df[\"hours_since_discharge\"] <= max_window_days * 24)].copy()\n",
    "\n",
    "    # --- 2. Group by Patient and Time ---\n",
    "    # Sort dataframe\n",
    "    df = df.sort_values(by=[\"subject_id\", \"hadm_id\", \"charttime\"])\n",
    "\n",
    "    # Group by 'subject_id', 'hadm_id', 'charttime'\n",
    "    grouped = df.groupby([\"subject_id\", \"hadm_id\", \"charttime\"])\n",
    "\n",
    "    n_timesteps = len(grouped)\n",
    "\n",
    "    # --- 3. Initialize Arrays ---\n",
    "    n_features = df[\"itemid\"].max() + 1  # Assumes itemids start at 0\n",
    "    x = np.zeros((n_features, n_timesteps))\n",
    "    masking = np.zeros_like(x)\n",
    "    timestamps = np.zeros(n_timesteps)\n",
    "    ids = []\n",
    "\n",
    "    # --- 4. Populate x, masking, and timestamps ---\n",
    "    for i, ((subj_id, adm_id, time), group) in enumerate(grouped):\n",
    "        timestamps[i] = (time - group[\"dischtime\"].iloc[0]).total_seconds() / 3600\n",
    "        ids.append({\"subject_id\": subj_id, \"hadm_id\": adm_id})\n",
    "        for _, row in group.iterrows():\n",
    "            x[int(row[\"itemid\"]), i] = row[\"valuenum\"]\n",
    "            masking[int(row[\"itemid\"]), i] = 1\n",
    "\n",
    "    # --- 5. Calculate delta ---\n",
    "    delta = np.zeros_like(x)\n",
    "    for i in range(1, n_timesteps):\n",
    "        time_gap = timestamps[i] - timestamps[i-1]\n",
    "        delta[:, i] = np.where(\n",
    "            masking[:, i-1] == 0,\n",
    "            time_gap + delta[:, i-1],  # Accumulate if previous value was missing\n",
    "            time_gap                   # Else use actual time gap\n",
    "        )\n",
    "\n",
    "    return x, masking, delta, timestamps, pd.DataFrame(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b18475",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, masking, delta, timestamps, ids = df_to_x_m_d(temp_df, max_window_days=7)\n",
    "\n",
    "print(\"x shape:\", x.shape)          # (max_itemid + 1, n_timesteps)\n",
    "print(\"masking shape:\", masking.shape)  # Same as x\n",
    "print(\"delta shape:\", delta.shape)    # Same as x\n",
    "print(\"Timestamps (hours before discharge):\", timestamps)\n",
    "# print(\"Patient IDs:\", ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0131120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a4840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps # Display first 5 timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c9640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
