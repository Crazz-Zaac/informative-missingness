{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a064a422",
   "metadata": {},
   "source": [
    "## Show the tables in schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2ec9e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:23:13,287 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-06-13 14:23:13,287 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-06-13 14:23:13,288 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-06-13 14:23:13,288 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-06-13 14:23:13,289 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-06-13 14:23:13,289 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "Schema: mimiciv_icu\n",
      "2025-06-13 14:23:13,291 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-13 14:23:13,291 INFO sqlalchemy.engine.Engine SELECT table_name FROM information_schema.tables WHERE table_schema = %(schema)s\n",
      "2025-06-13 14:23:13,291 INFO sqlalchemy.engine.Engine [generated in 0.00060s] {'schema': 'mimiciv_icu'}\n",
      "['caregiver', 'chartevents', 'datetimeevents', 'd_items', 'icustays', 'ingredientevents', 'inputevents', 'outputevents', 'procedureevents']\n",
      "Schema: mimiciv_hosp\n",
      "2025-06-13 14:23:13,295 INFO sqlalchemy.engine.Engine SELECT table_name FROM information_schema.tables WHERE table_schema = %(schema)s\n",
      "2025-06-13 14:23:13,295 INFO sqlalchemy.engine.Engine [cached since 0.004075s ago] {'schema': 'mimiciv_hosp'}\n",
      "['admissions', 'd_hcpcs', 'diagnoses_icd', 'd_icd_diagnoses', 'd_icd_procedures', 'd_labitems', 'drgcodes', 'emar_detail', 'emar', 'hcpcsevents', 'labevents', 'microbiologyevents', 'omr', 'patients', 'pharmacy', 'poe_detail', 'poe', 'prescriptions', 'procedures_icd', 'provider', 'services', 'transfers']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))  # adding the parent directory of 'notebooks' to sys.path\n",
    "from db_utils.db_setup import Database\n",
    "from sqlalchemy import text\n",
    "engine = Database()\n",
    "schema_list = [\"mimiciv_icu\", \"mimiciv_hosp\"]\n",
    "for schema in schema_list:\n",
    "    print(f\"Schema: {schema}\")\n",
    "    tables = Database.show_tables_in_schema(engine, schema)\n",
    "    print(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526cc2c0",
   "metadata": {},
   "source": [
    "# Getting all `labevents` data and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb8590",
   "metadata": {},
   "source": [
    "##### Fetching `demographic` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "url = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(url)\n",
    "conn = engine.connect()\n",
    "cursor = conn.connection.cursor()\n",
    "\n",
    "# Creating a TEMPORARY table\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TEMP TABLE temp_cohort (\n",
    "        subject_id INT,\n",
    "        hadm_id INT,\n",
    "        admittime TIMESTAMP,\n",
    "        dischtime TIMESTAMP,\n",
    "        target  INT\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Loading the CSV and insert into temp_cohort\n",
    "cohort_df = pd.read_csv('../assets/cohort1_target.csv')\n",
    "cohort_df['admittime'] = pd.to_datetime(cohort_df['admittime'], errors='coerce')\n",
    "cohort_df['dischtime'] = pd.to_datetime(cohort_df['dischtime'], errors='coerce')\n",
    "\n",
    "values = list(cohort_df.itertuples(index=False, name=None))\n",
    "execute_values(cursor,\n",
    "    \"INSERT INTO temp_cohort (subject_id, hadm_id, admittime, dischtime, target) VALUES %s\",\n",
    "    values\n",
    ")\n",
    "\n",
    "# Fetching demographic data from admissions table\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT \n",
    "        c.subject_id,\n",
    "        c.hadm_id,\n",
    "        c.admittime,\n",
    "        c.dischtime,\n",
    "        c.target,\n",
    "        p.gender,\n",
    "        p.anchor_age,\n",
    "        a.race\n",
    "    FROM temp_cohort c\n",
    "    JOIN mimiciv_hosp.admissions a ON c.hadm_id = a.hadm_id\n",
    "    JOIN mimiciv_hosp.patients p ON a.subject_id = p.subject_id\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Finally creating DataFrame \n",
    "columns = ['subject_id', 'hadm_id', 'admittime', 'dischtime', 'target', 'gender', 'anchor_age', 'race']\n",
    "final_df = pd.DataFrame(rows, columns=columns)\n",
    "# Save the final DataFrame to a Parquet file\n",
    "final_df['admittime'] = pd.to_datetime(final_df['admittime'], errors='coerce')\n",
    "final_df['dischtime'] = pd.to_datetime(final_df['dischtime'], errors='coerce')\n",
    "final_df['anchor_age'] = pd.to_numeric(final_df['anchor_age'], errors='coerce')\n",
    "final_df['target'] = pd.to_numeric(final_df['target'], errors='coerce')\n",
    "final_df.to_parquet(\"../dataset/raw/cohort_with_demographic_data.parquet\", index=False)\n",
    "\n",
    "# Finalize\n",
    "conn.connection.commit()\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "469830e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>target</th>\n",
       "      <th>gender</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10010231</td>\n",
       "      <td>23835132</td>\n",
       "      <td>2118-04-02 11:54:00</td>\n",
       "      <td>2118-04-07 11:26:00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10010231</td>\n",
       "      <td>23835132</td>\n",
       "      <td>2118-04-02 11:54:00</td>\n",
       "      <td>2118-04-07 11:26:00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10010231</td>\n",
       "      <td>23835132</td>\n",
       "      <td>2118-04-02 11:54:00</td>\n",
       "      <td>2118-04-07 11:26:00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10010231</td>\n",
       "      <td>24995642</td>\n",
       "      <td>2118-02-21 13:30:00</td>\n",
       "      <td>2118-02-26 16:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10010231</td>\n",
       "      <td>24995642</td>\n",
       "      <td>2118-02-21 13:30:00</td>\n",
       "      <td>2118-02-26 16:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id           admittime           dischtime  target  \\\n",
       "0    10010231  23835132 2118-04-02 11:54:00 2118-04-07 11:26:00       0   \n",
       "1    10010231  23835132 2118-04-02 11:54:00 2118-04-07 11:26:00       0   \n",
       "2    10010231  23835132 2118-04-02 11:54:00 2118-04-07 11:26:00       0   \n",
       "3    10010231  24995642 2118-02-21 13:30:00 2118-02-26 16:50:00       0   \n",
       "4    10010231  24995642 2118-02-21 13:30:00 2118-02-26 16:50:00       0   \n",
       "\n",
       "  gender  anchor_age                          race  \n",
       "0      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "1      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "2      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "3      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "4      M          57  HISPANIC/LATINO - GUATEMALAN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demog_df = pd.read_parquet(\"../dataset/raw/cohort_with_demographic_data.parquet\")\n",
    "demog_df.head(5)  # Display the first 5 rows of the raw Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d057f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'F'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demog_df['gender'].unique()  # Check unique values in the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad39fae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(91), np.int64(18))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demog_df['anchor_age'].max(), demog_df['anchor_age'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf9c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def map_race(race):\n",
    "    if pd.isna(race):\n",
    "        return 'Unknown or Not Reported'\n",
    "    \n",
    "    race = race.upper()\n",
    "    \n",
    "    if 'HISPANIC' in race or 'LATINO' in race or 'SOUTH AMERICAN' in race:\n",
    "        return 'Hispanic or Latino'\n",
    "    elif 'WHITE' in race:\n",
    "        return 'White'\n",
    "    elif 'BLACK' in race or 'AFRICAN' in race:\n",
    "        return 'Black or African American'\n",
    "    elif 'ASIAN' in race:\n",
    "        return 'Asian'\n",
    "    elif 'PACIFIC ISLANDER' in race or 'NATIVE HAWAIIAN' in race:\n",
    "        return 'Native Hawaiian or Other Pacific Islander'\n",
    "    elif 'AMERICAN INDIAN' in race or 'ALASKA NATIVE' in race:\n",
    "        return 'American Indian or Alaska Native'\n",
    "    elif 'DECLINED' in race or 'UNABLE' in race or 'UNKNOWN' in race:\n",
    "        return 'Unknown or Not Reported'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "le = LabelEncoder()\n",
    "demog_df['race_grouped'] = demog_df['race'].apply(map_race)  # apply your earlier grouping\n",
    "demog_df['race_target'] = le.fit_transform(demog_df['race_grouped'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22363332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ages: [57 58 60 72 59 73 75 74 41 61 65 45 71 78 24 50 77 63 69 91 44 42 76 84\n",
      " 56 67 55 80 46 68 47 32 53 33 52 48 30 85 66 83 87 64 81 36 26 79 28 43\n",
      " 70 27 62 25 49 54 89 21 20 82 34 51 40 29 31 86 38 23 88 39 35 22 37 18\n",
      " 19]\n",
      "Unique races: ['HISPANIC/LATINO - GUATEMALAN' 'WHITE' 'BLACK/AFRICAN AMERICAN' 'OTHER'\n",
      " 'ASIAN - CHINESE' 'ASIAN - SOUTH EAST ASIAN' 'ASIAN' 'UNKNOWN'\n",
      " 'WHITE - OTHER EUROPEAN' 'UNABLE TO OBTAIN' 'PATIENT DECLINED TO ANSWER'\n",
      " 'WHITE - RUSSIAN' 'SOUTH AMERICAN' 'WHITE - BRAZILIAN'\n",
      " 'HISPANIC/LATINO - DOMINICAN' 'BLACK/AFRICAN' 'PORTUGUESE'\n",
      " 'HISPANIC/LATINO - PUERTO RICAN' 'BLACK/CAPE VERDEAN'\n",
      " 'HISPANIC/LATINO - HONDURAN' 'HISPANIC/LATINO - CENTRAL AMERICAN'\n",
      " 'BLACK/CARIBBEAN ISLAND' 'ASIAN - ASIAN INDIAN'\n",
      " 'WHITE - EASTERN EUROPEAN' 'HISPANIC/LATINO - COLUMBIAN'\n",
      " 'HISPANIC/LATINO - SALVADORAN' 'HISPANIC/LATINO - CUBAN'\n",
      " 'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER' 'ASIAN - KOREAN'\n",
      " 'HISPANIC/LATINO - MEXICAN' 'AMERICAN INDIAN/ALASKA NATIVE']\n"
     ]
    }
   ],
   "source": [
    "# unique ages and races\n",
    "print(\"Unique ages:\", final_df['anchor_age'].unique())\n",
    "print(\"Unique races:\", final_df['race'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2b4217",
   "metadata": {},
   "source": [
    "##### Fetching labevents data prior `7` or `14` days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59e2632e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>itemid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>target</th>\n",
       "      <th>gender</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10010231</td>\n",
       "      <td>29368887</td>\n",
       "      <td>51233</td>\n",
       "      <td>2118-01-15 17:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2118-01-20 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10010231</td>\n",
       "      <td>29368887</td>\n",
       "      <td>51233</td>\n",
       "      <td>2118-01-15 17:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2118-01-20 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10010231</td>\n",
       "      <td>29368887</td>\n",
       "      <td>51233</td>\n",
       "      <td>2118-01-15 17:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2118-01-20 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10010231</td>\n",
       "      <td>21586397</td>\n",
       "      <td>51678</td>\n",
       "      <td>2117-12-19 06:20:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2117-12-23 16:51:00</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10010231</td>\n",
       "      <td>21586397</td>\n",
       "      <td>51678</td>\n",
       "      <td>2117-12-19 06:20:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2117-12-23 16:51:00</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>HISPANIC/LATINO - GUATEMALAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  itemid           charttime  valuenum  \\\n",
       "0    10010231  29368887   51233 2118-01-15 17:45:00       NaN   \n",
       "1    10010231  29368887   51233 2118-01-15 17:45:00       NaN   \n",
       "2    10010231  29368887   51233 2118-01-15 17:45:00       NaN   \n",
       "3    10010231  21586397   51678 2117-12-19 06:20:00       6.0   \n",
       "4    10010231  21586397   51678 2117-12-19 06:20:00       6.0   \n",
       "\n",
       "            dischtime  target gender  anchor_age                          race  \n",
       "0 2118-01-20 14:00:00       1      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "1 2118-01-20 14:00:00       1      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "2 2118-01-20 14:00:00       1      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "3 2117-12-23 16:51:00       1      M          57  HISPANIC/LATINO - GUATEMALAN  \n",
       "4 2117-12-23 16:51:00       1      M          57  HISPANIC/LATINO - GUATEMALAN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_parquet = pd.read_parquet(\"../dataset/raw/final_lab_events_7_days.parquet\")\n",
    "raw_parquet.head(5)  # Display the first 5 rows of the raw Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c260e3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10537677"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_parquet)  # Display the number of rows in the raw Parquet file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dcebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get all unique patient IDs\n",
    "patient_ids = pd.read_sql(\"SELECT DISTINCT subject_id FROM public.temp_cohort ORDER BY subject_id\", engine)\n",
    "\n",
    "lab_df = pd.DataFrame()\n",
    "\n",
    "# Process in patient batches\n",
    "batch_size = 100\n",
    "for i in range(0, len(patient_ids), batch_size):\n",
    "    batch = patient_ids.iloc[i:i+batch_size]\n",
    "    batch_list = tuple(batch['subject_id'])\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            le.subject_id, \n",
    "            le.hadm_id, \n",
    "            le.itemid, \n",
    "            le.charttime, \n",
    "            le.valuenum,\n",
    "            tc.dischtime,\n",
    "            tc.target\n",
    "        FROM mimiciv_hosp.labevents le\n",
    "        JOIN public.temp_cohort tc\n",
    "          ON le.subject_id = tc.subject_id\n",
    "         AND le.hadm_id = tc.hadm_id\n",
    "        WHERE le.charttime BETWEEN (tc.dischtime - INTERVAL '7 days') AND tc.dischtime\n",
    "        AND le.subject_id IN {batch_list}\n",
    "    \"\"\"\n",
    "    \n",
    "    chunk = pd.read_sql(query, engine)\n",
    "    # Process your chunk\n",
    "    lab_df = pd.concat([lab_df, chunk], ignore_index=True)\n",
    "# Reset index after concat\n",
    "lab_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5118bd",
   "metadata": {},
   "source": [
    "# Pre-processing data\n",
    "\n",
    "### Aggregating on an `hourly` basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8ac671b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10537677"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "patient_data_df = pl.read_parquet(\"../dataset/raw/lab_events_7_days_prior.parquet\")\n",
    "len(patient_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a3fd1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def assign_time_bin(hours_before_discharge, window_hours=6):\n",
    "    \"\"\"Assign records to fixed time bins (e.g., 0-6h, 6-12h).\n",
    "    Example: For a 6-hour window:\n",
    "        0.5h → bin 0, 6.1h → bin 6, 23h → bin 18\n",
    "    \"\"\"\n",
    "    return (np.floor(hours_before_discharge / window_hours) * window_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ef466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features shape: (2177, 13238)\n",
      "Binary features shape: (2177, 18554)\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamps\n",
    "df = patient_data_df.copy()\n",
    "df[\"charttime\"] = pd.to_datetime(df[\"charttime\"])\n",
    "df[\"dischtime\"] = pd.to_datetime(df[\"dischtime\"])\n",
    "\n",
    "# Calculate hours before discharge\n",
    "df[\"hours_before_discharge\"] = (\n",
    "    df[\"dischtime\"] - df[\"charttime\"]\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "# Filter to 24-hour window (or any max window you need)\n",
    "df = df[(df[\"hours_before_discharge\"] >= 0) & (df[\"hours_before_discharge\"] <= 168)]\n",
    "\n",
    "# Assign bins (e.g., 6-hour windows)\n",
    "df[\"time_bin\"] = assign_time_bin(df[\"hours_before_discharge\"], window_hours=12)\n",
    "# print(df[\"time_bin\"])\n",
    "\n",
    "# Create feature IDs (e.g., \"itemid_123_last_6h\")\n",
    "df[\"feature_id\"] = (\n",
    "    \"itemid_\" + df[\"itemid\"].astype(str) + \"_last_\" + df[\"time_bin\"].astype(str) + \"h\"\n",
    ")\n",
    "\n",
    "# Numeric features (mean/max)\n",
    "numeric_features = df.pivot_table(\n",
    "    index=\"subject_id\",\n",
    "    columns=\"feature_id\",\n",
    "    values=\"valuenum\",\n",
    "    aggfunc=\"mean\", # \"max\"],  # Customize as needed\n",
    ")\n",
    "\n",
    "numeric_features = numeric_features.fillna(-999)  # Fill NaNs with a sentinel value\n",
    "\n",
    "# Binary features (measurement existence)\n",
    "df[\"has_measurement\"] = 1\n",
    "binary_features = df.pivot_table(\n",
    "    index=\"subject_id\",\n",
    "    columns=\"feature_id\",\n",
    "    values=\"has_measurement\",\n",
    "    aggfunc=\"max\",  # 1 if any measurement exists in the bin\n",
    "    fill_value=0\n",
    ")\n",
    "binary_features.columns = [f\"{col}_measured\" for col in binary_features.columns]\n",
    "\n",
    "targets = df[[\"subject_id\", \"target\"]].drop_duplicates().set_index(\"subject_id\")\n",
    "\n",
    "numeric_features = numeric_features.join(targets).reset_index()\n",
    "binary_features = binary_features.join(targets).reset_index()\n",
    "print(f\"Numeric features shape: {numeric_features.shape}\")\n",
    "print(f\"Binary features shape: {binary_features.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69756088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features['subject_id'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef823cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>itemid_50801_last_164.0h</th>\n",
       "      <th>itemid_50801_last_66.0h</th>\n",
       "      <th>itemid_50802_last_0.0h</th>\n",
       "      <th>itemid_50802_last_10.0h</th>\n",
       "      <th>itemid_50802_last_100.0h</th>\n",
       "      <th>itemid_50802_last_102.0h</th>\n",
       "      <th>itemid_50802_last_104.0h</th>\n",
       "      <th>itemid_50802_last_106.0h</th>\n",
       "      <th>itemid_50802_last_108.0h</th>\n",
       "      <th>...</th>\n",
       "      <th>itemid_53174_last_60.0h</th>\n",
       "      <th>itemid_53174_last_72.0h</th>\n",
       "      <th>itemid_53174_last_74.0h</th>\n",
       "      <th>itemid_53174_last_76.0h</th>\n",
       "      <th>itemid_53174_last_78.0h</th>\n",
       "      <th>itemid_53174_last_84.0h</th>\n",
       "      <th>itemid_53174_last_96.0h</th>\n",
       "      <th>itemid_53174_last_98.0h</th>\n",
       "      <th>itemid_53180_last_44.0h</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10010231</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10010231</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10012768</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 13238 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  itemid_50801_last_164.0h  itemid_50801_last_66.0h  \\\n",
       "0    10010231                    -999.0                   -999.0   \n",
       "1    10010231                    -999.0                   -999.0   \n",
       "2    10012768                    -999.0                   -999.0   \n",
       "\n",
       "   itemid_50802_last_0.0h  itemid_50802_last_10.0h  itemid_50802_last_100.0h  \\\n",
       "0                  -999.0                   -999.0                    -999.0   \n",
       "1                  -999.0                   -999.0                    -999.0   \n",
       "2                  -999.0                   -999.0                    -999.0   \n",
       "\n",
       "   itemid_50802_last_102.0h  itemid_50802_last_104.0h  \\\n",
       "0                    -999.0                    -999.0   \n",
       "1                    -999.0                    -999.0   \n",
       "2                    -999.0                    -999.0   \n",
       "\n",
       "   itemid_50802_last_106.0h  itemid_50802_last_108.0h  ...  \\\n",
       "0                    -999.0                    -999.0  ...   \n",
       "1                    -999.0                    -999.0  ...   \n",
       "2                    -999.0                    -999.0  ...   \n",
       "\n",
       "   itemid_53174_last_60.0h  itemid_53174_last_72.0h  itemid_53174_last_74.0h  \\\n",
       "0                   -999.0                   -999.0                   -999.0   \n",
       "1                   -999.0                   -999.0                   -999.0   \n",
       "2                   -999.0                   -999.0                   -999.0   \n",
       "\n",
       "   itemid_53174_last_76.0h  itemid_53174_last_78.0h  itemid_53174_last_84.0h  \\\n",
       "0                   -999.0                   -999.0                   -999.0   \n",
       "1                   -999.0                   -999.0                   -999.0   \n",
       "2                   -999.0                   -999.0                   -999.0   \n",
       "\n",
       "   itemid_53174_last_96.0h  itemid_53174_last_98.0h  itemid_53180_last_44.0h  \\\n",
       "0                   -999.0                   -999.0                   -999.0   \n",
       "1                   -999.0                   -999.0                   -999.0   \n",
       "2                   -999.0                   -999.0                   -999.0   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       0  \n",
       "2       0  \n",
       "\n",
       "[3 rows x 13238 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce1a9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features['hadm_id'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a8ccde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd25920d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b515bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 290346 records within 12-hour window...\n",
      "Created numeric features: (3076, 1459)\n",
      "Created binary features: (3099, 2036)\n",
      "Filtered down to 290346 rows from 3518649\n",
      "Number of unique hadm_ids: 3099\n"
     ]
    }
   ],
   "source": [
    "# Create a copy and convert timestamps\n",
    "new_df = patient_data_df.copy()\n",
    "new_df[\"charttime\"] = pd.to_datetime(new_df[\"charttime\"])\n",
    "new_df[\"dischtime\"] = pd.to_datetime(new_df[\"dischtime\"])\n",
    "\n",
    "# Calculate hours before discharge\n",
    "new_df[\"hours_before_discharge\"] = (new_df[\"dischtime\"] - new_df[\"charttime\"]).dt.total_seconds() / 3600\n",
    "\n",
    "# Filter to 12-hour window (0 to 12 hours inclusive)\n",
    "new_df_filtered = new_df[\n",
    "    (new_df[\"hours_before_discharge\"] >= 0) & (new_df[\"hours_before_discharge\"] <= 12)\n",
    "].copy()\n",
    "\n",
    "print(f\"Processing {len(new_df_filtered)} records within 12-hour window...\")\n",
    "\n",
    "# Create hourly bins (1-12)\n",
    "new_df_filtered[\"hour_bin\"] = (np.floor(new_df_filtered[\"hours_before_discharge\"]) + 1).astype(int)\n",
    "new_df_filtered[\"hour_bin\"] = new_df_filtered[\"hour_bin\"].clip(upper=12)  # Cap at 12\n",
    "\n",
    "# Create feature_id with hour bin\n",
    "new_df_filtered[\"feature_id\"] = (\n",
    "    \"itemid_\" + \n",
    "    new_df_filtered[\"itemid\"].astype(str) + \n",
    "    \"_last_\" + \n",
    "    new_df_filtered[\"hour_bin\"].astype(str) + \n",
    "    \"h\"\n",
    ")\n",
    "\n",
    "# Pivot numeric features (mean aggregation)\n",
    "numeric_pivot = new_df_filtered.pivot_table(\n",
    "    index=\"hadm_id\",\n",
    "    columns=\"feature_id\",\n",
    "    values=\"valuenum\",\n",
    "    aggfunc=\"mean\",\n",
    "    # fill_value=np.nan,\n",
    ")\n",
    "numeric_filled = numeric_pivot.fillna(-999)\n",
    "\n",
    "# Pivot binary features (existence indicator)\n",
    "new_df_filtered[\"has_measurement\"] = 1\n",
    "binary_pivot = new_df_filtered.pivot_table(\n",
    "    index=\"hadm_id\",\n",
    "    columns=\"feature_id\",\n",
    "    values=\"has_measurement\",\n",
    "    aggfunc=\"max\",  # 1 if any measurement exists\n",
    "    fill_value=0,\n",
    ")\n",
    "binary_pivot.columns = [col + \"_measured\" for col in binary_pivot.columns]\n",
    "\n",
    "# combined_features = numeric_filled.join(targets).reset_index()\n",
    "\n",
    "# Get targets\n",
    "targets = new_df_filtered[[\"hadm_id\", \"target\"]].drop_duplicates().set_index(\"hadm_id\")\n",
    "\n",
    "# Combine features with targets (NO forward/backward fill)\n",
    "numeric_features = numeric_filled.join(targets).reset_index()\n",
    "binary_features = binary_pivot.join(targets).reset_index()\n",
    "\n",
    "print(f\"Created numeric features: {numeric_features.shape}\")\n",
    "print(f\"Created binary features: {binary_features.shape}\")\n",
    "print(f\"Filtered down to {len(new_df_filtered)} rows from {len(new_df)}\")\n",
    "print(f\"Number of unique hadm_ids: {new_df_filtered['hadm_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0a9b7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368        9\n",
       "369        9\n",
       "370        9\n",
       "371        9\n",
       "372        9\n",
       "          ..\n",
       "3518463    5\n",
       "3518464    5\n",
       "3518465    5\n",
       "3518466    5\n",
       "3518467    5\n",
       "Name: hours_before_discharge, Length: 290346, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.floor(new_df_filtered[\"hours_before_discharge\"])).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0fe38a",
   "metadata": {},
   "source": [
    "# Training a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d128b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac0b51e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
